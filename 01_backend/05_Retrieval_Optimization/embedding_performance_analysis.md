# 임베딩 모델 성능이 하이브리드 검색에 미치는 영향 분석

## 📊 현재 상황 요약

| 검색 전략 | Recall@1 | Recall@5 | MRR | 성능 순위 |
| :--- | :---: | :---: | :---: | :---: |
| **BM25 Only** | **92.0%** | **98.0%** | **0.947** | 🏆 1위 |
| Hybrid (RRF) | 80.0% | 96.0% | 0.877 | 2위 |
| Hybrid (Weighted) | 70.0% | 94.0% | 0.804 | 3위 |
| **Vector Only** | **66.0%** | 96.0% | 0.760 | 4위 |

## 🔍 핵심 문제: 임베딩 모델 성능 부족

### 1. Vector Only의 낮은 성능 (Recall@1 66%)

**원인 분석:**
- `BGE-m3` 모델이 한국사 고유명사(인물명, 사건명, 서적명)에 대한 학습이 부족
- 한자어 고유명사가 임베딩 공간에서 유사도가 낮게 계산됨
- LLM 재평가 결과: 보정 후에도 72%로 여전히 낮음

### 2. 하이브리드 검색이 BM25보다 낮은 이유

**수학적 분석:**

#### Hybrid (Weighted 0.6:0.4)의 경우:
```
Hybrid Score = 0.6 × Vector_Score + 0.4 × BM25_Score
```

- Vector가 66% 성능 → 정규화된 점수가 낮음
- BM25가 92% 성능 → 정규화된 점수가 높음
- **결과:** Vector의 낮은 점수가 하이브리드 점수를 끌어내림
- **최종 성능:** 70% (BM25 92%보다 22%p 낮음)

#### Hybrid (RRF)의 경우:
```
RRF Score = 1/(60 + Rank_Vector) + 1/(60 + Rank_BM25)
```

- RRF는 순위 기반이므로 점수 스케일 차이에 덜 민감
- Vector가 1위에 정답을 놓치면 RRF 점수가 크게 감소
- **결과:** 80% (BM25보다는 낮지만 Vector보다는 높음)

### 3. 왜 하이브리드가 단독보다 나쁠까?

**이론적으로는:**
- Vector: 맥락 질문에 강함 (예: "임진왜란의 원인은?")
- BM25: 키워드 질문에 강함 (예: "세종대왕")
- **하이브리드:** 두 장점을 모두 취해야 함

**실제로는:**
- Vector 성능이 너무 낮아서(66%) BM25의 강점(92%)을 상쇄시킴
- Vector가 틀린 케이스에서 BM25가 맞았어도, 하이브리드 점수는 Vector의 낮은 점수로 인해 떨어짐

## 💡 시나리오 분석: 임베딩 모델 성능에 따른 하이브리드 효과

### 시나리오 A: 현재 상황 (Vector 66%)
- BM25 Only: 92% ✅ 최선
- Hybrid: 70-80% ❌ BM25보다 낮음
- **결론:** BM25 단독 사용이 최선

### 시나리오 B: Vector 성능 개선 (Vector 85% 가정)
- BM25 Only: 92%
- Hybrid: 약 88-90% (추정)
- **결론:** 여전히 BM25가 우수하지만, Hybrid도 경쟁력 있음

### 시나리오 C: Vector 성능 극대화 (Vector 95% 가정)
- BM25 Only: 92%
- Hybrid: 약 93-95% (추정) ✅ 최선
- **결론:** 하이브리드가 최고 성능

## 🎯 결론

**현재 상황:**
1. ✅ **임베딩 모델(BGE-m3) 성능이 낮아서** (Recall@1 66%)
2. ✅ **하이브리드 검색 성능이 떨어짐** (70-80%)
3. ✅ **BM25 단독이 최선** (92%)

**향후 개선 방향:**
1. **더 나은 임베딩 모델 탐색:**
   - 한국어/한국사 특화 모델
   - 예: `jhgan/ko-sbert-nli`, `BM-K/KoSimCSE-roberta-multitask`
   
2. **임베딩 모델 파인튜닝:**
   - 한국사 도메인 데이터로 BGE-m3 파인튜닝
   - 고유명사 임베딩 품질 개선

3. **하이브리드 재검토:**
   - Vector 성능이 85% 이상이 되면 하이브리드 효과 재평가
   - 가중치 튜닝 (예: Vector 0.3, BM25 0.7)

## 📝 면접 대비 포인트

> "하이브리드 검색을 구현했지만, 벤치마크 결과 **임베딩 모델(BGE-m3)의 성능이 낮아서**(Recall@1 66%) 하이브리드 검색이 BM25 단독(92%)보다 성능이 떨어졌습니다.
> 
> 이는 Vector의 낮은 점수가 하이브리드 점수를 끌어내리기 때문입니다. 따라서 현재는 **BM25 단독을 사용**하고 있으며, 향후 더 나은 임베딩 모델을 찾거나 파인튜닝을 통해 Vector 성능을 개선하면 하이브리드 검색의 잠재력을 재검토할 계획입니다."

