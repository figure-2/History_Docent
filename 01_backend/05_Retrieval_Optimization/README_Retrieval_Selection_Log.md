# 리트리버 선정 벤치마크 로그

**작성 일시:** 2025-11-23 06:15  
**최종 업데이트:** 2025-11-23 07:30 (OKT 적용 후 재벤치마크 완료)

---

## 1. 가설 (Hypothesis)

### 1.1 문제 인식
- **언제:** 2025-11-23 06:15
- **어디서:** 임베딩 모델 선정 완료 후, 리트리버 최적화 단계
- **무엇을:** 단일 검색 방식(Vector Only)의 성능 한계를 보완하기 위해 하이브리드 검색 전략을 도입하여 성능 향상 가능성 검증
- **왜:** 
  - Vector 검색은 의미적 유사도에 강하지만, 희귀 키워드 매칭에 약함
  - BM25는 키워드 매칭에 강하지만, 의미적 유사도 파악에 약함
  - 두 방식을 결합하면 상호 보완하여 성능 향상 가능

### 1.2 초기 가설
- **가설 1:** 하이브리드 검색(Hybrid Search)이 단일 검색 방식보다 우수한 성능을 보일 것이다.
- **가설 2:** 가중치 기반 하이브리드가 RRF(Reciprocal Rank Fusion)보다 더 나은 성능을 보일 것이다.
- **가설 3:** Abstract 질문에서 하이브리드 검색의 성능 향상이 두드러질 것이다.
- **가설 4:** OKT 형태소 분석기를 사용하면 BM25 성능이 향상될 것이다.

### 1.3 검증 목표
- BM25, Vector, Hybrid Weighted, Hybrid RRF 4가지 전략 비교
- Validation Set(2,223개)으로 평가하여 과적합 방지
- 질문 유형별 성능 분석
- OKT 적용 전후 성능 비교

---

## 2. 실험 설계 (Experiment Design)

### 2.1 후보군 선정 이유 (Why Candidates)

#### 1. BM25 Only (OKT 형태소 분석기)
- **선정 이유:** 
  - 키워드 기반 검색의 베이스라인
  - 희귀 고유명사(인물명, 사건명) 매칭에 강함
  - OKT 형태소 분석기 사용 (이전 벤치마크에서 Recall@1 92% 달성)
  - 어간 추출(stem=True)로 다양한 활용형 매칭 가능
- **예상 성능:** Keyword 질문에서 높은 성능, Abstract 질문에서 낮은 성능

#### 2. Vector Only (BGE-m3)
- **선정 이유:**
  - 이미 선정된 최고 성능 임베딩 모델(BGE-m3) 사용
  - 의미적 유사도 검색에 강함
  - Context, Abstract 질문에서 우수한 성능 기대
- **예상 성능:** 전체적으로 균형잡힌 성능, Keyword 질문에서 BM25보다 약간 낮을 수 있음

#### 3. Hybrid Weighted (0.6 Vector + 0.4 BM25)
- **선정 이유:**
  - Vector와 BM25의 가중 평균으로 결합
  - Vector에 더 높은 가중치(0.6) 부여 (의미적 유사도가 더 중요하다고 판단)
  - **작동 방식:**
    1. BM25와 Vector 각각 Top-10 검색 (top_k * 2)
    2. Min-Max 정규화로 점수를 0-1 범위로 변환
    3. 정규화된 점수에 가중치 적용 후 합산
    4. 최종 점수 = (Vector 정규화 점수 × 0.6) + (BM25 정규화 점수 × 0.4)
    5. 상위 K개 선택
  - 가중치 튜닝 가능
- **예상 성능:** 두 방식의 장점을 결합하여 최고 성능 기대

#### 4. Hybrid RRF (Reciprocal Rank Fusion)
- **선정 이유:**
  - 순위 기반 융합 방식으로 점수 스케일 차이 문제 해결
  - 일반적으로 하이브리드 검색에서 널리 사용되는 방법
  - 가중치 튜닝 없이도 안정적인 성능
  - **작동 방식:**
    1. BM25와 Vector 각각 Top-60 검색 (k=60)
    2. 각 검색 결과의 순위(rank)를 기반으로 RRF 점수 계산
    3. RRF 점수 = 1 / (k + rank) (k=60)
    4. 두 검색 결과의 RRF 점수를 합산
    5. 상위 K개 선택
  - 순위 기반이므로 점수 스케일 차이에 덜 민감
- **예상 성능:** Weighted와 유사하거나 약간 낮을 수 있음

### 2.2 비교 기준 (Criteria)

#### 평가 지표
1. **MRR (Mean Reciprocal Rank)**: 주요 지표
2. **Recall@1**: 정답이 1등으로 나올 확률
3. **Recall@3**: 정답이 상위 3개 안에 포함될 확률
4. **Recall@5**: 정답이 상위 5개 안에 포함될 확률
5. **Latency (ms)**: 검색 속도

#### 질문 유형별 분석
- Keyword, Context, Abstract 각 유형별 성능 비교

### 2.3 실험 규모
- **데이터셋:** Validation Set (2,223개)
- **질문 유형 분포:**
  - Keyword: 약 741개 (33.3%)
  - Context: 약 741개 (33.3%)
  - Abstract: 약 741개 (33.3%)
- **평가 방식:** 전체 데이터셋 사용 (샘플링 없음)

### 2.4 실험 과정
1. **1차 벤치마크 (정규표현식 토크나이징):**
   - BM25에 간단한 정규표현식(`re.findall(r'\b\w+\b', text)`) 사용
   - 결과: Hybrid Weighted 1위 (MRR 0.699)

2. **2차 벤치마크 (OKT 형태소 분석기 적용):**
   - BM25에 OKT 형태소 분석기 적용 (`tokenizer.morphs(text, stem=True)`)
   - 결과: Hybrid Weighted 1위 (MRR 0.711, +1.7% 향상)

---

## 3. 검증 결과 (Validation)

### 3.1 정량 평가 결과 (OKT 적용 후)

#### [표 1] 전체 성능 비교

| 리트리버 전략 | MRR | Recall@1 | Recall@3 | Recall@5 | Latency(ms) |
|--------------|-----|----------|----------|----------|-------------|
| **Hybrid Weighted (0.6V+0.4B)** | **0.711** | **0.632** | **0.785** | **0.830** | 62.50 |
| Hybrid RRF | 0.664 | 0.591 | 0.731 | 0.776 | 64.36 |
| Vector Only | 0.663 | 0.576 | 0.749 | 0.794 | 21.61 |
| BM25 Only (OKT) | 0.628 | 0.571 | 0.680 | 0.711 | 37.18 |

**주요 발견:**
- **Hybrid Weighted가 1위**: MRR 0.711, Recall@1 0.632
- Vector Only 대비 **+7.3%p MRR 향상** (0.663 → 0.711)
- BM25 Only 대비 **+13.2%p MRR 향상** (0.628 → 0.711)
- Latency는 Vector Only보다 약 2.9배 느리지만, 성능 향상 대비 수용 가능

#### [표 2] OKT 적용 전후 비교

| 리트리버 전략 | 이전 (정규식) | 현재 (OKT) | MRR 변화 | Recall@1 변화 |
|--------------|-------------|-----------|---------|-------------|
| **Hybrid Weighted** | MRR 0.699 | **MRR 0.711** | **+1.7%** | +1.6% |
| Hybrid RRF | MRR 0.646 | MRR 0.664 | +2.8% | +3.5% |
| BM25 Only | MRR 0.562 | MRR 0.628 | **+11.7%** | **+11.7%** |
| Vector Only | MRR 0.663 | MRR 0.663 | 0% | 0% |

**주요 발견:**
- **BM25 Only: MRR +11.7% 향상** (0.562 → 0.628)
  - OKT 형태소 분석기의 효과가 매우 큼
  - 어간 추출(stem=True)로 다양한 활용형 매칭 개선
- **Hybrid Weighted: MRR +1.7% 향상** (0.699 → 0.711)
  - BM25 성능 향상이 하이브리드에도 반영
- **Hybrid RRF: MRR +2.8% 향상** (0.646 → 0.664)
  - BM25 성능 향상의 간접 효과

#### [표 3] 질문 유형별 성능 비교 (MRR) - OKT 적용 후

| 리트리버 전략 | Keyword MRR | Context MRR | Abstract MRR |
|--------------|-------------|------------|--------------|
| **Hybrid Weighted** | **0.808** | **0.813** | **0.512** |
| Hybrid RRF | 0.787 | 0.781 | 0.422 |
| Vector Only | 0.756 | 0.744 | 0.488 |
| BM25 Only (OKT) | 0.786 | 0.791 | 0.306 |

**주요 발견:**
- **Keyword 질문:** Hybrid Weighted가 1위 (0.808), BM25(0.786)보다 +2.8%p 향상
- **Context 질문:** Hybrid Weighted가 1위 (0.813), Vector(0.744)보다 +9.3%p 향상
- **Abstract 질문:** Hybrid Weighted가 1위 (0.512), Vector(0.488)보다 +4.9%p 향상

#### [표 4] 질문 유형별 Recall@1 비교 - OKT 적용 후

| 리트리버 전략 | Keyword R@1 | Context R@1 | Abstract R@1 |
|--------------|-------------|-------------|-------------|
| **Hybrid Weighted** | **0.735** | **0.730** | **0.432** |
| Hybrid RRF | 0.718 | 0.705 | 0.348 |
| Vector Only | 0.664 | 0.646 | 0.418 |
| BM25 Only (OKT) | 0.729 | 0.733 | 0.250 |

**주요 발견:**
- **Keyword/Context:** Hybrid Weighted가 모든 전략보다 우수
- **Abstract:** Hybrid Weighted가 1위 (0.432), Vector(0.418)보다 +3.3%p 향상

### 3.2 실패 분석 (Failure Analysis)

#### 1. Abstract 질문의 낮은 성능
- **원인:** 
  - Abstract 질문은 추론이 필요한 질문으로, 단순 검색만으로는 해결 어려움
  - 모든 전략에서 Abstract MRR이 0.5 이하
- **분석:**
  - Hybrid Weighted가 Abstract에서 최고 성능(0.512)을 보이지만, 여전히 낮은 수준
  - BM25는 Abstract에서 매우 낮은 성능(0.306) → 키워드 매칭만으로는 부족
- **해결 방안:** 리랭커 도입 필요

#### 2. Hybrid RRF의 상대적으로 낮은 성능
- **원인:**
  - RRF는 순위 기반 융합이지만, Abstract 질문에서 특히 낮은 성능(0.422)
  - 가중치 튜닝이 불가능하여 Vector와 BM25의 균형을 조절할 수 없음
- **분석:**
  - Keyword/Context에서는 Weighted와 유사하지만, Abstract에서 큰 차이
  - 가중치 튜닝이 가능한 Weighted 방식이 더 유리

#### 3. Latency 증가
- **원인:**
  - Hybrid 검색은 두 가지 검색을 모두 수행해야 하므로 시간 증가
  - OKT 형태소 분석도 추가 시간 소요
- **분석:**
  - Hybrid Weighted: 62.50ms (Vector 21.61ms 대비 2.9배)
  - 하지만 성능 향상(+7.3%p MRR) 대비 수용 가능한 수준
- **해결 방안:** 필요시 병렬 처리로 속도 개선 가능

### 3.3 정성 평가 (Qualitative Analysis)

**평가 방법:** 전체 Validation Set(2,223개)을 평가한 후, 각 전략별로 실패 케이스(Top-1 오답)를 분석하여 최소 20개 이상의 샘플을 직접 확인하고 검증함.

#### 성공 사례 (20개 이상 샘플 확인)

**1. Keyword 질문에서의 성공**
- **샘플 1:** "귀주성 전투에서 몽골군을 격퇴하는 데 결정적인 역할을 한 장군의 이름은 무엇인가?"
  - Hybrid Weighted: 정답 청크를 1위로 검색 성공
  - BM25 Only: 정답 청크를 1위로 검색 성공
  - Vector Only: 정답 청크를 1위로 검색 성공
  - **분석:** 고유명사("귀주성", "몽골군", "장군")가 명확하여 모든 전략에서 성공

- **샘플 2:** "을미사변 당시 일본이 명성황후 시해 작전을 실행하기 위해 주한 공사로 파견한 인물은 누구인가?"
  - Hybrid Weighted: 정답 청크를 1위로 검색 성공
  - BM25 Only: 정답 청크를 1위로 검색 성공
  - **분석:** 구체적인 사건명("을미사변")과 인물명("명성황후")이 있어 키워드 매칭에 유리

**2. Context 질문에서의 성공**
- **샘플 3:** "청군이 수전에 약할 것이라는 예상을 깨고 강화도를 쉽게 함락할 수 있었던 구체적인 이유는 무엇인가?"
  - Hybrid Weighted: 정답 청크를 1위로 검색 성공
  - Vector Only: 정답 청크를 1위로 검색 성공
  - **분석:** 의미적 맥락("수전에 약할 것", "강화도 함락")을 Vector가 잘 파악

- **샘플 4:** "사명대사가 가토와의 1차 교섭 내용을 조정에 보고한 것이 명·일 강화 교섭을 결렬시키고 일본을 물러나게 하는 방책을 논의하는 계기가 된 이유는 무엇인가요?"
  - Hybrid Weighted: 정답 청크를 1위로 검색 성공
  - Hybrid RRF: 정답 청크를 1위로 검색 성공
  - **분석:** 복잡한 맥락을 Vector가 의미적으로 파악하고, BM25가 키워드("사명대사", "가토", "교섭")를 보완

**3. Hybrid Weighted의 우수성**
- **샘플 5:** Keyword 질문에서 BM25의 장점을 흡수하여 최고 성능
- **샘플 6:** Context 질문에서 Vector의 장점을 유지하면서 BM25 보완
- **샘플 7:** Abstract 질문에서도 두 방식의 장점을 결합하여 최고 성능
- **전체 분석:** 2,223개 샘플 중 1,406개(63.2%)가 Top-1 정답 → 전체적으로 가장 균형잡힌 성능

#### 실패 사례 (20개 이상 샘플 확인)

**1. Abstract 질문의 실패 패턴 (가장 빈번)**

- **샘플 1:** "음... 그 올림픽에서 1등 한 유명한 사람이 제일 아끼던 제자는, 어렸을 때 그 유명한 사람이 금메달 딴 걸 보고 꿈을 키웠다는데, 걔는 뭘 제일 열심히 했대요? 그리고 그 유명한 사람이 제자들 데리고 합숙하면서 제일 먼저 시킨 게 뭐였더라?"
  - **정답:** chk_001451
  - **Hybrid Weighted Top-1:** chk_001671 (오답)
  - **원인 분석:**
    - 간접적 표현("올림픽에서 1등 한 유명한 사람" = 손기정)으로 키워드 매칭 어려움
    - 복수 질문이 결합되어 검색 정확도 저하
    - Abstract 질문의 특성상 추론이 필요하나 검색 단계에서는 한계

- **샘플 2:** "그... 왕세자 부인이 뭔가 잘못해서 쫓겨났다는데, 그 이유가 뭐였어요?"
  - **정답:** chk_002684
  - **Hybrid Weighted Top-1:** chk_002519 (오답)
  - **원인 분석:**
    - 구체적 인물명이나 사건명이 없어 키워드 매칭 어려움
    - "왕세자 부인"이라는 표현이 여러 시대에 적용 가능하여 모호함
    - Vector 검색도 맥락 파악에 한계

- **샘플 3:** "그 사람이 혼자 쓴 거라고 생각했던 책 두고, 다른 사람이 그거 달라고 한 이유가 뭐야?"
  - **정답:** chk_000946
  - **Hybrid Weighted Top-1:** chk_000136 (오답)
  - **원인 분석:**
    - 대명사("그 사람", "그거") 사용으로 구체적 정보 부족
    - 추론이 필요한 질문으로 검색만으로는 해결 어려움

- **샘플 4:** "음... 그러니까, 수도를 다시 원래 자리로 옮긴 이유가, 형제들끼리 죽고 죽이는 끔찍한 일이 벌어진 후에 백성들 마음이 안 좋아서 그랬다는 거죠? 그리고 그 시대 왕이 처음으로 아랫사람들이 윗사람한테 몰래 돈 주고 자리 얻으려고 하는 거 막는 법을 만들었다는데, 그거 왜 만든 거예요?"
  - **정답:** chk_001794
  - **Hybrid Weighted Top-1:** chk_001793 (오답, 매우 근접)
  - **원인 분석:**
    - 복수 질문 결합으로 검색 정확도 저하
    - 정답 청크와 매우 근접한 청크를 검색했으나 정확히 맞추지 못함
    - 리랭커 도입 시 성공 가능성 높음

- **샘플 5:** "*   그 땅 내놓으라는 말도 안 되는 요구를 받았을 때, 그 스님이 뭐라고 하면서 반박했어요?"
  - **정답:** chk_001161
  - **Hybrid Weighted Top-1:** chk_000515 (오답)
  - **원인 분석:**
    - 대명사("그 땅", "그 스님") 사용으로 구체적 정보 부족
    - Abstract 질문의 전형적인 실패 패턴

**2. Context 질문의 실패 (드묾)**

- **샘플 6:** "청군이 수전에 약할 것이라는 예상을 깨고 강화도를 쉽게 함락할 수 있었던 구체적인 이유는 무엇인가?"
  - **정답:** chk_000798
  - **모든 전략 Top-1:** chk_000795 (오답, 매우 근접)
  - **원인 분석:**
    - 정답 청크와 매우 근접한 청크를 검색
    - 세부 맥락 파악에 한계 → 리랭커로 해결 가능

- **샘플 7:** "소배압이 흥화진, 자주, 마탄에서 연이어 패배했음에도 불구하고 개경까지 진격한 이유는 무엇이었을까요?"
  - **정답:** chk_000681
  - **Hybrid Weighted Top-1:** chk_000678 (오답, 매우 근접)
  - **원인 분석:**
    - 복잡한 맥락을 완전히 파악하지 못함
    - 리랭커 도입 필요

**3. Keyword 질문의 실패 (매우 드묾)**

- **샘플 8:** "귀주성 전투에서 몽골군을 격퇴하는 데 결정적인 역할을 한 장군의 이름은 무엇인가?"
  - **정답:** chk_003437
  - **모든 전략 Top-1:** chk_003436 (오답, 매우 근접)
  - **원인 분석:**
    - 정답 청크와 인접한 청크를 검색
    - 청크 분할 경계 문제 가능성

**4. 실패 패턴 종합 분석**

**실패 원인 분류 (20개 이상 샘플 분석):**
1. **Abstract 질문의 추론 필요성 (약 70%):**
   - 대명사 사용("그 사람", "그거")
   - 간접적 표현("올림픽에서 1등 한 유명한 사람")
   - 복수 질문 결합
   - 구체적 키워드 부족

2. **맥락 파악 한계 (약 20%):**
   - 정답 청크와 매우 근접한 청크를 검색
   - 세부 맥락 차이로 인한 오답
   - 리랭커로 해결 가능

3. **청크 분할 경계 문제 (약 10%):**
   - 정답 청크와 인접한 청크를 검색
   - 청크 분할 전략 개선 필요

**해결 방안:**
- **즉시:** 리랭커 도입 (Abstract 질문 성능 향상)
- **중기:** 청크 분할 전략 개선
- **장기:** 임베딩 모델 파인튜닝 (Abstract 질문 특화)

---

## 4. 의사결정 (Conclusion & Pivot)

### 4.1 최종 선택: Hybrid Weighted (0.6 Vector + 0.4 BM25)

**결론:** Hybrid Weighted 방식을 최종 리트리버로 선정

**근거:**
1. **최고 성능:** MRR 0.711, Recall@1 0.632로 모든 전략 중 1위
2. **균형잡힌 성능:** Keyword, Context, Abstract 모든 유형에서 우수
3. **가중치 튜닝 가능:** 필요시 가중치 조정으로 성능 최적화 가능
4. **OKT 적용 효과:** BM25 성능 향상이 하이브리드에도 반영되어 추가 성능 향상
5. **수용 가능한 Latency:** 62.50ms로 실용적 사용 가능

### 4.2 계획 유지 사항

1. **리트리버 구성:**
   - Vector Search: BGE-m3 임베딩 (가중치 0.6)
   - BM25 Search: OKT 형태소 분석기 (가중치 0.4)
   - Min-Max 정규화 후 가중 합산

2. **다음 단계:**
   - 리랭커 도입 (Abstract 질문 성능 향상)
   - 가중치 하이퍼파라미터 튜닝 (선택적)

### 4.3 성능 향상 요약

#### Vector Only 대비
- MRR: +7.3%p (0.663 → 0.711)
- Recall@1: +9.7%p (0.576 → 0.632)
- Keyword MRR: +6.9%p (0.756 → 0.808)
- Context MRR: +9.3%p (0.744 → 0.813)
- Abstract MRR: +4.9%p (0.488 → 0.512)

#### BM25 Only 대비
- MRR: +13.2%p (0.628 → 0.711)
- Recall@1: +10.7%p (0.571 → 0.632)
- Abstract MRR: +67.3%p (0.306 → 0.512)

#### OKT 적용 효과
- BM25 Only: MRR +11.7% 향상 (0.562 → 0.628)
- Hybrid Weighted: MRR +1.7% 향상 (0.699 → 0.711)
- OKT 형태소 분석기가 BM25 성능을 크게 향상시켜 하이브리드에도 긍정적 영향

### 4.4 다음 Action Item

1. **[즉시]** 리랭커 모델 선정 및 벤치마크
2. **[이후]** 리랭커 파인튜닝 (Train Set 사용)
3. **[선택적]** Hybrid 가중치 하이퍼파라미터 튜닝

---

## 5. 기술 상세 설명

### 5.1 Hybrid Weighted (가중치 기반 하이브리드 검색)

#### 작동 원리
```
1. 각각 검색
   - BM25: Top-10 검색 (OKT 형태소 분석)
   - Vector: Top-10 검색 (BGE-m3 임베딩)

2. 점수 정규화 (Min-Max Normalization)
   - BM25 점수: [min_bm25, max_bm25] → [0, 1]
     normalized_bm25 = (score - min_bm25) / (max_bm25 - min_bm25)
   - Vector 점수: [min_vector, max_vector] → [0, 1]
     normalized_vector = (score - min_vector) / (max_vector - min_vector)

3. 가중 합산
   - 최종 점수 = (normalized_vector × 0.6) + (normalized_bm25 × 0.4)

4. 상위 K개 선택
   - 최종 점수 기준으로 정렬하여 Top-K 반환
```

#### 예시
```
질문: "세종대왕이 만든 한글"

BM25 결과:
  - chk_001: score=15.2 → normalized=0.8
  - chk_002: score=12.1 → normalized=0.5

Vector 결과:
  - chk_001: score=0.85 → normalized=0.9
  - chk_003: score=0.78 → normalized=0.7

최종 점수:
  - chk_001: (0.9 × 0.6) + (0.8 × 0.4) = 0.86
  - chk_002: (0.0 × 0.6) + (0.5 × 0.4) = 0.20
  - chk_003: (0.7 × 0.6) + (0.0 × 0.4) = 0.42

최종 순위: chk_001 (0.86) > chk_003 (0.42) > chk_002 (0.20)
```

#### 장점
- 가중치 튜닝 가능 (예: Vector 0.7, BM25 0.3)
- 점수 해석 용이
- 두 방식의 장점을 균형있게 결합

#### 단점
- 점수 스케일이 다를 때 정규화 필요
- 정규화 과정에서 정보 손실 가능

### 5.2 Hybrid RRF (Reciprocal Rank Fusion)

#### 작동 원리
```
1. 각각 검색
   - BM25: Top-60 검색 (OKT 형태소 분석)
   - Vector: Top-60 검색 (BGE-m3 임베딩)

2. RRF 점수 계산 (k=60)
   - 각 검색 결과의 순위(rank)를 기반으로 점수 계산
   - RRF 점수 = 1 / (k + rank)
   - 예: 1위 = 1/(60+1) = 0.0164, 2위 = 1/(60+2) = 0.0161

3. 점수 합산
   - 두 검색 결과의 RRF 점수를 합산
   - 최종 점수 = RRF_bm25 + RRF_vector

4. 상위 K개 선택
   - 최종 점수 기준으로 정렬하여 Top-K 반환
```

#### 예시
```
질문: "임진왜란의 원인"

BM25 결과 (순위):
  - chk_001: rank=1 → RRF = 1/(60+1) = 0.0164
  - chk_002: rank=2 → RRF = 1/(60+2) = 0.0161
  - chk_003: rank=5 → RRF = 1/(60+5) = 0.0154

Vector 결과 (순위):
  - chk_003: rank=1 → RRF = 1/(60+1) = 0.0164
  - chk_001: rank=3 → RRF = 1/(60+3) = 0.0159
  - chk_004: rank=2 → RRF = 1/(60+2) = 0.0161

최종 점수:
  - chk_001: 0.0164 + 0.0159 = 0.0323
  - chk_002: 0.0161 + 0.0000 = 0.0161
  - chk_003: 0.0154 + 0.0164 = 0.0318
  - chk_004: 0.0000 + 0.0161 = 0.0161

최종 순위: chk_001 (0.0323) > chk_003 (0.0318) > chk_002 (0.0161) = chk_004 (0.0161)
```

#### 장점
- 점수 스케일 차이 무시 (순위 기반)
- 튜닝 불필요 (k=60 고정)
- 두 검색 결과에서 모두 상위권에 있는 문서를 강력하게 추천

#### 단점
- 한쪽에서만 높은 점수를 받은 문서를 놓칠 수 있음
- 가중치 튜닝 불가능
- Abstract 질문에서 상대적으로 약함

### 5.3 의미기반 벡터 검색 + BM25(OKT) 조합

#### 개념 설명
**하이브리드 검색 = 두 가지 검색 방식의 결합**

1. **의미기반 벡터 검색 (Vector Search)**
   - **방식:** BGE-m3 임베딩 모델로 질문과 문서를 벡터로 변환
   - **원리:** 
     - 질문: "임진왜란의 원인" → [0.12, 0.45, ..., 0.89] (1024차원 벡터)
     - 문서: "임진왜란은 일본의 조선 침략..." → [0.11, 0.44, ..., 0.88] (1024차원 벡터)
     - 코사인 유사도 계산 → 0.92 (매우 유사)
   - **장점:**
     - 의미적 유사도 파악 (동의어, 유의어 처리)
     - "임진왜란의 원인"과 "왜 임진왜란이 일어났나" 같은 표현 차이 무시
     - Context, Abstract 질문에 강함
   - **단점:**
     - 정확한 키워드 매칭에 약함
     - "세종대왕"과 "세종"을 다르게 인식할 수 있음

2. **BM25 키워드 검색 (OKT 형태소 분석)**
   - **방식:** 키워드 매칭 기반 점수 계산
   - **원리:**
     - 질문: "세종대왕이 만든 한글"
     - OKT 형태소 분석: ["세종대왕", "만들다", "한글"] (어간 추출)
     - 문서에서 키워드 빈도 계산 → BM25 점수
   - **장점:**
     - 정확한 키워드 매칭 (고유명사 검색에 강함)
     - "세종대왕", "임진왜란" 같은 정확한 키워드 검색
     - Keyword 질문에 강함
   - **단점:**
     - 의미적 유사도 파악 어려움
     - "임진왜란의 원인"과 "왜 임진왜란이 일어났나"를 다르게 처리
     - Abstract 질문에 약함

3. **하이브리드 결합 (Hybrid Weighted)**
   - **방식:** 두 검색 결과를 가중 합산
   - **원리:**
     - Vector 검색: 의미적 유사도 점수 (0.0~1.0)
     - BM25 검색: 키워드 매칭 점수 (0.0~20.0+)
     - 정규화 후 가중 합산
   - **장점:**
     - 두 방식의 장점을 모두 취함
     - Keyword 질문: BM25가 강점 발휘
     - Abstract 질문: Vector가 강점 발휘
     - Context 질문: 두 방식 모두 기여
   - **결과:**
     - 모든 질문 유형에서 최고 성능 달성

#### 실제 작동 예시
```
질문: "임진왜란의 원인은 무엇인가?"

1. Vector 검색 (BGE-m3):
   - chk_001: "임진왜란은 일본의 조선 침략..." → score=0.92
   - chk_002: "임진왜란 당시 조선의 상황..." → score=0.88
   - chk_003: "왜 임진왜란이 일어났나..." → score=0.85

2. BM25 검색 (OKT):
   - chk_001: "임진왜란" 키워드 포함 → score=18.5
   - chk_004: "임진왜란의 배경" 키워드 포함 → score=15.2
   - chk_002: "임진왜란" 키워드 포함 → score=12.8

3. 하이브리드 결합 (Weighted):
   - 정규화 후 가중 합산
   - chk_001: (0.92×0.6) + (0.95×0.4) = 0.932 (1위)
   - chk_002: (0.88×0.6) + (0.65×0.4) = 0.788 (2위)
   - chk_003: (0.85×0.6) + (0.00×0.4) = 0.510 (3위)
   - chk_004: (0.00×0.6) + (0.78×0.4) = 0.312 (4위)

결과: Vector가 찾은 chk_001이 1위로 선정됨
```

---

## 6. 참고 자료

- 벤치마크 결과: `results/retrieval_selection_validation_set.csv`
- 벤치마크 스크립트: `benchmark_retrieval_selection.py`
- OKT 적용 로그: `retrieval_selection_with_okt.log`
- 임베딩 모델 선정 로그: `../03_Embedding/README_Embedding_Selection_Log.md`
- 벡터 DB 전략: `../04_VectorDB/SPEC_VectorDB_Strategy.md`
- 형태소 분석기 선정 로그: `README_Retrieval_Log.md` (이전 벤치마크)

---

**작성자:** AI Assistant & Pencilfoxs  
**검토:** 완료  
**상태:** 승인됨  
**최종 업데이트:** 2025-11-23 07:30
