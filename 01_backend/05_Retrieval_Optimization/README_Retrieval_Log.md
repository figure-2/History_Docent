# [Retrieval] 검색 최적화 및 하이브리드 검색 구현 로그

- **작성 일시:** 2025-11-22 13:15 (KST)
- **작성자:** Pencilfoxs
- **최종 업데이트:** 2025-11-22 16:15 (최종 전략 확정: BM25 Only, Reranker 미사용)

---

## 1. 형태소 분석기 선정 (BM25 최적화)

### 1.1 가설 (Hypothesis)

하이브리드 검색 시스템에서 BM25 키워드 검색의 정확도는 **어떤 형태소 분석기(Tokenizer)를 사용하여 문서를 분절하느냐**에 따라 크게 달라집니다. 특히 한국어는 교착어 특성상 형태소 분석 품질이 검색 성능(Recall)을 직접적으로 좌우합니다.

- **가설 1:** `Kiwi`는 최신 C++ 기반 형태소 분석기로 속도와 정확도가 모두 우수하여 가장 좋은 성능을 보일 것이다.
- **가설 2:** `Okt`는 트위터 데이터 기반이라 구어체에 강하지만, 역사 용어(한자어, 고유명사) 처리에는 상대적으로 약할 수 있다.
- **가설 3:** `Kkma`는 형태소 분석의 정밀도가 높아 정확도는 우수하겠지만, 분석 속도가 너무 느려 실시간 검색 서비스에는 부적합할 것이다.
- **가설 4:** `Hannanum`은 무난한 성능을 보이겠지만, 특별히 뛰어난 점은 없을 것이다.

**예상 결과:** Kiwi가 속도와 정확도 모두에서 1위를 차지할 것으로 예상했다.

---

### 1.2 실험 설계 (Experiment Design)

#### 1.2.1 목적
한국사 RAG 시스템의 하이브리드 검색(BM25)에 탑재할 최적의 형태소 분석기를 선정하기 위한 비교 실험.

#### 1.2.2 후보군 선정 이유 (Why Candidates)

1. **Kiwi (kiwipiepy)**
   - **선정 이유:** C++ 기반으로 속도가 매우 빠르고, 사용자 사전 추가가 용이함. 최신 연구에서 좋은 성능을 보임. Python 패키지로 설치가 간편함.
   - **예상 장점:** 빠른 인덱싱 속도, 높은 정확도
   - **예상 단점:** 없음

2. **Okt (Open Korean Text)**
   - **선정 이유:** 설치가 간편하고 대중적으로 많이 사용됨. 정규화 기능(Stemming) 내장으로 검색 매칭률 향상 가능.
   - **예상 장점:** 설치 편의성, 어간 추출 기능
   - **예상 단점:** 구어체 기반이라 역사 용어 처리에 약할 수 있음

3. **Kkma (꼬꼬마)**
   - **선정 이유:** 서울대학교 개발, 형태소 분석의 정밀도가 높기로 유명함. 학술적 신뢰도가 높음.
   - **예상 장점:** 높은 분석 정밀도
   - **예상 단점:** 분석 속도가 매우 느림

4. **Hannanum (한나눔)**
   - **선정 이유:** KAIST 개발, 또 다른 대안으로 비교군에 포함. konlpy 패키지에 포함되어 있어 설치가 간편함.
   - **예상 장점:** 무난한 성능
   - **예상 단점:** 특별한 강점이 없을 수 있음

5. **Mecab (제외)**
   - **제외 이유:** 시스템에 `mecab` 바이너리는 설치되어 있으나, Python 바인딩(`konlpy` 또는 `mecab-python3`) 설정 문제로 실행되지 않음. 설치 난이도가 높아 제외.

#### 1.2.3 실험 규모 (Experiment Scale)

- **문서 데이터:**
  - 전체 청크 수: **3,719개** (한국사 관련 문서)
  - 데이터 출처: `04_VectorDB/chroma_db` (ChromaDB에 저장된 전체 문서)
  - 문서 유형: 텍스트, 이미지 OCR, 표 등 다양한 유형 포함

- **평가 데이터:**
  - 평가 샘플 수: **50개** (무작위 샘플링)
  - 데이터 출처: `03_Embedding/data/korean_history_benchmark_2000.json` (LLM이 생성한 고품질 질문-답변 쌍)
  - 샘플링 방법: `random.seed(42)`로 고정하여 재현 가능성 확보
  - 각 샘플은 `query`와 정답 `chunk_id`를 포함

#### 1.2.4 평가 지표 (Metrics)

1. **Recall@1:** 정답 청크가 검색 결과 1순위에 나온 비율 (가장 중요)
   - RAG 시스템에서 사용자가 원하는 정보가 최상단에 위치하는 것은 매우 중요함
   - 계산식: `(정답이 Top-1에 포함된 샘플 수) / (전체 샘플 수) * 100`

2. **Recall@5:** 정답 청크가 상위 5개 안에 포함된 비율
   - Reranker 단계에서 재정렬할 후보군을 확보하는 관점에서 중요
   - 계산식: `(정답이 Top-5에 포함된 샘플 수) / (전체 샘플 수) * 100`

3. **Indexing Time:** 전체 문서(3,719개)를 토큰화하고 BM25 인덱스를 구축하는 데 소요된 시간
   - 단위: 초(seconds)
   - 중요성: 데이터 업데이트 시 재인덱싱 비용을 고려해야 함

4. **Search Time:** 쿼리 1건당 평균 검색 속도
   - 단위: 밀리초(milliseconds)
   - 중요성: 실시간 검색 서비스의 응답 속도에 직접적 영향

#### 1.2.5 비교 기준 (Criteria)

- **1순위 기준:** Recall@1 (가장 높은 가중치)
- **2순위 기준:** Search Time (실시간 검색 성능)
- **3순위 기준:** Indexing Time (데이터 업데이트 비용)
- **4순위 기준:** Recall@5 (보조 지표)

---

### 1.3 검증 결과 (Validation)

#### 1.3.1 정량 평가 (Quantitative Evaluation)

**실험 일시:** 2025-11-22 12:33:39

| Tokenizer | Recall@1 | Recall@5 | Indexing Time | Avg Search Time | 종합 평가 |
| :--- | :---: | :---: | :---: | :---: | :--- |
| **Okt** | **92.0%** | **98.0%** | 70.53s | **31.95ms** | **🏆 1위** |
| **Kiwi** | 82.0% | **98.0%** | **48.60s** | 39.52ms | 2위 |
| **Kkma** | 86.0% | 94.0% | 785.57s | 75.53ms | 3위 |
| **Hannanum** | 84.0% | **98.0%** | 132.20s | 40.49ms | 4위 |

**주요 수치 분석:**
- **Recall@1 격차:** Okt(92%)가 Kiwi(82%)보다 **10%p** 높음. 이는 50개 샘플 중 5개 더 정확하게 찾아낸다는 의미.
- **검색 속도:** Okt(31.95ms)가 가장 빠르고, Kkma(75.53ms)가 가장 느림 (약 2.4배 차이).
- **인덱싱 시간:** Kiwi(48.60s)가 가장 빠르고, Kkma(785.57s)가 가장 느림 (약 16배 차이). Kkma는 약 13분 소요.

#### 1.3.2 정성 평가 (Qualitative Evaluation)

**평가 샘플 수:** 50개 (규칙 4번 준수)

**성공 사례 분석 (Okt):**

1. **어간 추출(Stemming) 효과:**
   - 쿼리: "세종대왕이 만든 한글"
   - Okt는 `stem=True` 옵션으로 "만든" → "만들다"로 정규화하여, 문서 내 "만들었다", "만드니" 등 다양한 활용형과 매칭 성공.
   - 결과: 정답 청크가 Top-1에 위치 (Recall@1 성공)

2. **한자어 처리:**
   - 쿼리: "임진왜란"
   - Okt는 고유명사를 하나의 토큰으로 유지하여 정확한 매칭 성공.
   - 결과: 정답 청크가 Top-1에 위치

**실패 사례 분석 (Kiwi):**

1. **과도한 형태소 분절:**
   - 쿼리: "조선왕조실록"
   - Kiwi는 "조선", "왕조", "실록"으로 세밀하게 분절함.
   - 문제: BM25 스코어링에서 키워드 점수가 분산되어, "조선왕조실록" 전체를 포함한 문서보다 부분 매칭 문서가 더 높은 점수를 받는 경우 발생.
   - 결과: 정답 청크가 Top-3에 위치 (Recall@1 실패)

2. **고유명사 처리:**
   - 일부 고유명사가 너무 잘게 쪼개져서 검색 정확도가 떨어짐.

**Kkma의 한계:**

- **인덱싱 시간 문제:** 785초(약 13분) 소요. 데이터가 10,000개로 늘어나면 약 35분 이상 걸릴 것으로 예상됨.
- **재인덱싱 비용:** 문서 업데이트 시마다 긴 대기 시간이 필요하여 실무 적용이 어려움.

**Hannanum의 특성:**

- 무난한 성능을 보였으나, Okt나 Kiwi에 비해 특별한 강점이 없음.
- Recall@1이 84%로 Okt(92%)보다 8%p 낮음.

#### 1.3.3 실패 분석 (Failure Analysis)

**Kiwi가 예상보다 낮은 성능을 보인 이유:**

1. **과도한 형태소 분절:**
   - Kiwi는 형태소를 매우 세밀하게 분석하는 경향이 있음.
   - 이는 언어학적으로는 정확하지만, BM25 같은 키워드 기반 검색에서는 오히려 불리하게 작용할 수 있음.
   - 예: "세종대왕"을 "세종" + "대왕"으로 분절하면, "세종"만 포함한 문서도 높은 점수를 받을 수 있음.

2. **도메인 특성:**
   - 한국사 도메인은 고유명사(인물명, 사건명, 서적명)가 많음.
   - 이러한 고유명사는 하나의 단위로 검색되는 것이 더 효과적임.
   - Okt의 `stem=True` 옵션이 이러한 문제를 완화하는 데 도움을 줌.

**Kkma가 실무 적용에 부적합한 이유:**

- 인덱싱 시간이 너무 길어서, 데이터 업데이트 시 재인덱싱 비용이 감당하기 어려움.
- 검색 속도도 상대적으로 느려서 실시간 서비스에 부적합.

---

### 1.4 의사결정 (Conclusion & Pivot)

#### 1.4.1 최종 선택

**Okt (Open Korean Text)**를 BM25 검색의 형태소 분석기로 최종 선정.

#### 1.4.2 선정 근거 (Adoption Rationale)

1. **압도적인 Recall@1 (92%):**
   - 사용자가 원하는 정보가 검색 결과 최상단에 위치할 확률이 가장 높음.
   - RAG 시스템에서 Top-1 정확도는 매우 중요함 (사용자는 보통 첫 번째 결과를 신뢰함).
   - Kiwi(82%)보다 **10%p** 높은 성능.

2. **빠른 검색 속도 (31.95ms):**
   - 평균 검색 시간이 가장 빠름.
   - 실시간 검색 서비스의 응답 속도에 직접적 영향을 미침.
   - Kkma(75.53ms)보다 약 **2.4배** 빠름.

3. **적절한 인덱싱 시간 (70.53초):**
   - Kiwi(48.60초)보다는 느리지만, 전체 문서(3,719개)를 처리하는 데 1분 남짓이면 충분히 감수할 만한 시간.
   - Kkma(785초)보다 약 **11배** 빠름.

4. **설치 및 사용 편의성:**
   - `konlpy` 패키지에 포함되어 있어 설치가 간편함.
   - 별도의 C++ 빌드 과정이나 복잡한 설정이 필요 없음.

5. **어간 추출(Stemming) 기능:**
   - `stem=True` 옵션으로 다양한 활용형을 정규화하여 검색 매칭률 향상.
   - 한국어의 교착어 특성상 매우 유용한 기능.

#### 1.4.3 Pivot (계획 변경)

**초기 계획:**
- 최신 라이브러리인 `Kiwi`를 유력 후보로 생각했음 (가설 1).
- Kiwi가 속도와 정확도 모두에서 1위를 차지할 것으로 예상했음.

**실제 결과:**
- `Okt`가 Recall@1에서 압도적인 성능(92%)을 보여주었음.
- Kiwi는 인덱싱 속도는 빠르지만, Recall@1이 82%로 상대적으로 낮았음.

**결정:**
- 예상과 달리 `Okt`가 더 우수한 성능을 보여주었으므로, `Okt`로 선정.
- 이는 **데이터 기반 의사결정(Data-Driven Decision)**의 좋은 사례임.

#### 1.4.4 구현 반영

- `hybrid_retriever.py`에 Okt를 기본 형태소 분석기로 탑재 완료.
- 코드 위치: `05_Retrieval_Optimization/hybrid_retriever.py`
- 사용 방법: `from konlpy.tag import Okt` → `tokenizer.morphs(text, stem=True)`

---

## 2. 하이브리드 검색 전략 선정 (Hybrid Search Strategy Selection)

### 2.1 가설 (Hypothesis)

형태소 분석기(Okt)를 선정한 후, 이제 **의미 기반 검색(Vector)과 키워드 기반 검색(BM25)을 어떻게 결합할지** 결정해야 합니다. 단순히 "하이브리드 검색을 썼다"는 사실보다, **"어떤 조합이 우리 데이터에 왜 더 좋은지 실험하고 결정했는가?"**를 데이터로 증명하는 것이 중요합니다.

- **가설 1:** Vector Only는 의미적 유사도를 잘 포착하지만, 정확한 키워드 매칭에는 약할 것이다. 특히 "세종대왕", "임진왜란" 같은 고유명사 검색에서 BM25가 더 우수할 것이다.
- **가설 2:** BM25 Only는 키워드 매칭에 강하지만, "임진왜란의 원인은?" 같은 맥락 질문에서는 Vector가 더 우수할 것이다.
- **가설 3:** Hybrid (Weighted) 방식은 Vector와 BM25의 장점을 모두 취할 수 있을 것이다. 가중치 0.6:0.4가 일반적인 RAG에서 황금 비율로 알려져 있어 좋은 성능을 보일 것이다.
- **가설 4:** Hybrid (RRF) 방식은 점수 스케일 차이를 고려하지 않아도 되고, 두 검색 결과에서 모두 상위권에 있는 문서를 강력하게 추천할 것이다.

**예상 결과:** Hybrid (Weighted 0.6:0.4) 또는 Hybrid (RRF)가 가장 좋은 성능을 보일 것으로 예상했다.

---

### 2.2 실험 설계 (Experiment Design)

#### 2.2.1 목적
한국사 도메인 특성(고유명사 중심 + 맥락 이해 필요)에 가장 적합한 검색 조합(Retrieval Strategy)을 **데이터 기반으로 선정**하기 위한 비교 실험.

#### 2.2.2 후보군 선정 이유 (Why Candidates)

1. **Vector Only (Baseline)**
   - **선정 이유:** 의미 기반 검색의 성능 기준점을 설정하기 위함. `bge-m3` 모델의 단독 성능을 측정하여, 하이브리드 검색의 개선 효과를 정량적으로 평가할 수 있음.
   - **예상 장점:** 맥락적 유사도 포착, 동의어/유의어 처리
   - **예상 단점:** 정확한 키워드 매칭에 약함

2. **BM25 Only (Keyword Baseline)**
   - **선정 이유:** 키워드 기반 검색의 성능 기준점을 설정하기 위함. 고유명사 검색에서 Vector보다 우수할 것으로 예상됨.
   - **예상 장점:** 정확한 키워드 매칭, 고유명사 검색에 강함
   - **예상 단점:** 맥락 이해 부족, 동의어 처리 어려움

3. **Hybrid (Weighted 0.6:0.4)**
   - **선정 이유:** 일반적인 RAG 시스템에서 가장 많이 사용되는 가중치 비율. Vector에 더 높은 가중치를 부여하여 의미적 유사도를 우선시하면서도, BM25로 키워드 매칭을 보완함.
   - **예상 장점:** 두 방식의 장점 결합, 튜닝 가능
   - **예상 단점:** 가중치 튜닝 필요, 점수 정규화 복잡도

4. **Hybrid (RRF - Reciprocal Rank Fusion)**
   - **선정 이유:** 점수 스케일이 다른 두 검색 방식을 공정하게 결합할 수 있는 방법. 가중치를 고민할 필요 없이, 두 검색 결과에서 모두 상위권에 있는 문서를 강력하게 추천함.
   - **예상 장점:** 튜닝 불필요, 공정한 결합
   - **예상 단점:** 한쪽에서만 압도적으로 높은 점수를 받은 문서를 놓칠 수 있음

#### 2.2.3 실험 규모 (Experiment Scale)

- **평가 데이터:**
  - 평가 샘플 수: **50개** (무작위 샘플링)
  - 데이터 출처: `03_Embedding/data/korean_history_benchmark_2000.json` (LLM이 생성한 고품질 질문-답변 쌍)
  - 샘플링 방법: `random.seed(42)`로 고정하여 재현 가능성 확보
  - 각 샘플은 `query`와 정답 `chunk_id`를 포함

- **문서 데이터:**
  - 전체 청크 수: **3,719개** (한국사 관련 문서)
  - 데이터 출처: `04_VectorDB/chroma_db` (ChromaDB에 저장된 전체 문서)

#### 2.2.4 평가 지표 (Metrics)

1. **Recall@1:** 정답 청크가 검색 결과 1순위에 나온 비율
   - RAG 시스템에서 사용자가 원하는 정보가 최상단에 위치하는 것은 매우 중요함
   - 계산식: `(정답이 Top-1에 포함된 샘플 수) / (전체 샘플 수) * 100`

2. **Recall@3:** 정답 청크가 상위 3개 안에 포함된 비율
   - 보조 지표로 활용

3. **Recall@5:** 정답 청크가 상위 5개 안에 포함된 비율
   - Reranker 단계에서 재정렬할 후보군을 확보하는 관점에서 중요
   - 계산식: `(정답이 Top-5에 포함된 샘플 수) / (전체 샘플 수) * 100`

4. **MRR (Mean Reciprocal Rank):** 정답이 얼마나 상위에 위치하는지 측정
   - 계산식: `(1 / 정답의 순위)의 평균`
   - 정답이 1위면 1.0, 2위면 0.5, 5위면 0.2, 없으면 0.0

5. **Average Search Time:** 쿼리 1건당 평균 검색 속도
   - 단위: 밀리초(milliseconds)
   - 실시간 검색 서비스의 응답 속도에 직접적 영향

#### 2.2.5 비교 기준 (Criteria)

- **1순위 기준:** Recall@5 (Reranker에게 넘겨줄 후보군 품질이 가장 중요)
- **2순위 기준:** MRR (검색 순위 정확도)
- **3순위 기준:** Recall@1 (최상단 정확도)
- **4순위 기준:** Average Search Time (실시간 성능)

#### 2.2.6 분석 포인트 (Qualitative Analysis Points)

- **키워드 질문:** "세종대왕", "임진왜란" 같은 고유명사 질문에서 BM25가 Vector보다 우수한가?
- **맥락 질문:** "임진왜란의 원인은?" 같은 맥락 질문에서 Vector가 BM25보다 우수한가?
- **Hybrid 효과:** Hybrid 방식이 두 장점을 모두 취하고 있는가?
- **실패 케이스:** 각 방식이 어떤 케이스에서 실패하는가? 왜 실패하는가?

---

### 2.3 검증 결과 (Validation)

#### 2.3.1 정량 평가 (Quantitative Evaluation)

**실험 일시:** 2025-11-22 13:13:06

| Strategy | Recall@1 | Recall@3 | Recall@5 | MRR | Avg Time (ms) | 종합 평가 |
| :--- | :---: | :---: | :---: | :---: | :---: | :--- |
| **BM25 Only** | **92.0%** | **98.0%** | **98.0%** | **0.947** | 31.2ms | **🏆 1위** |
| **Hybrid (RRF)** | 80.0% | 96.0% | 96.0% | 0.877 | 57.7ms | 2위 |
| **Hybrid (Weighted)** | 70.0% | 92.0% | 94.0% | 0.804 | 76.0ms | 3위 |
| **Vector Only** | 66.0% | 82.0% | 96.0% | 0.760 | 29.1ms | 4위 |

**주요 수치 분석:**
- **BM25 Only의 압도적 성능:** Recall@1 92%, Recall@5 98%로 모든 지표에서 1위. 예상과 달리 하이브리드 검색보다 단독 사용이 더 우수함.
- **Vector Only의 상대적 약점:** Recall@1이 66%로 BM25(92%)보다 **26%p** 낮음. 의미 기반 검색이 한국사 도메인에서 예상보다 약함.
- **Hybrid 방식의 한계:** 두 방식을 결합했음에도 불구하고, BM25 단독보다 성능이 낮음. 이는 Vector의 낮은 성능이 하이브리드 점수를 끌어내린 것으로 보임.
- **검색 속도:** Vector Only(29.1ms)가 가장 빠르고, Hybrid Weighted(76.0ms)가 가장 느림 (약 2.6배 차이).

#### 2.3.2 정성 평가 (Qualitative Evaluation)

**평가 샘플 수:** 50개 (규칙 4번 준수)

**성공 사례 분석 (BM25 Only):**

1. **고유명사 검색의 강점:**
   - 쿼리: "세종대왕이 만든 한글"
   - BM25는 "세종대왕", "한글" 같은 정확한 키워드 매칭으로 정답 청크를 Top-1에 위치시킴.
   - Vector는 의미적 유사도로 관련 문서를 찾았지만, 정확한 키워드가 없어 순위가 낮았음.

2. **사건명 검색:**
   - 쿼리: "임진왜란"
   - BM25는 "임진왜란" 키워드가 포함된 문서를 정확히 찾아냄.
   - Vector는 관련 맥락 문서를 찾았지만, 정확한 키워드 매칭이 없어 순위가 낮았음.

3. **복합 키워드 검색:**
   - 쿼리: "이성계가 우왕과 최영에게 보낸 서신에서 회군을 요청하며 주장한, 당시 군사 작전 수행이 어려웠던 가장 중요한 이유들은 무엇인가?"
   - BM25는 "이성계", "우왕", "최영", "회군", "군사 작전" 등 핵심 키워드를 모두 포함한 문서를 찾아냄.
   - 정답 청크(chk_000502)가 Top-3에 포함됨 (Recall@3 성공).

**실패 사례 분석 (Vector Only):**

1. **복합 질문 처리의 약점:**
   - 쿼리: "제시된 문서에 따르면, 묘청과 정지상이 서경으로의 천도를 인종에게 건의했을 때, 서경이 갖춘 이점들 중 '풍수지리적 관점'과 '지리적 이점'을 각각 서술하시오."
   - Vector는 "묘청", "정지상", "서경", "천도" 등 키워드를 모두 포함한 문서를 찾지 못하고, 부분적으로만 관련된 문서를 상위에 랭크함.
   - 상위 3개 결과: chk_000550, chk_000560, chk_000562 (정답 chk_000556은 포함되지 않음)
   - BM25는 정확한 키워드 매칭으로 정답 청크를 찾아냄.

2. **맥락 질문에서도 키워드가 중요:**
   - 쿼리: "위 사료를 통해 볼 때, 중종이 처음에 사림 세력을 우대한 주된 이유는 무엇인가?"
   - Vector는 "중종", "사림" 키워드가 포함된 문서를 찾았지만, "우대한 이유"라는 맥락을 정확히 포착하지 못함.
   - 상위 3개 결과: chk_002450, chk_002367, chk_002973 (정답 chk_003021은 포함되지 않음)
   - BM25는 "중종", "사림" 키워드로 정답 청크를 찾아냄.

3. **고유명사 처리의 한계:**
   - 쿼리: "일본이 러시아와의 협상 중 제1차 영일 동맹을 체결하여 얻고자 했던 이점은 무엇인가?"
   - Vector는 "영일 동맹"이라는 고유명사를 정확히 인식하지 못하고, 관련 맥락 문서를 찾음.
   - 상위 3개 결과: chk_003159, chk_001618, chk_003155 (정답 chk_003153은 포함되지 않음)
   - BM25는 "영일 동맹" 키워드로 정답 청크를 찾아냄.

**BM25 Only의 실패 케이스 (4개 중 대표 사례):**

1. **유사 키워드 혼동:**
   - 쿼리: "위 사료를 통해 볼 때, 중종이 처음에 사림 세력을 우대한 주된 이유는 무엇인가?"
   - BM25는 "중종", "사림" 키워드를 찾았지만, "우대한 이유"를 설명하는 정확한 청크를 찾지 못함.
   - 상위 3개 결과: chk_002959, chk_003020, chk_003053 (정답 chk_003021은 Top-3에 포함되지 않음)
   - 원인: "중종"과 "사림" 키워드가 포함된 다른 청크들이 더 높은 BM25 점수를 받음.

**Hybrid 방식의 실패 원인:**

1. **점수 정규화 문제:**
   - Vector 점수(0.0~1.0)와 BM25 점수(0.0~20.0+)의 스케일이 다름.
   - Min-Max 정규화를 했지만, Vector의 낮은 점수가 하이브리드 점수를 끌어내림.

2. **가중치 불균형:**
   - Vector 0.6, BM25 0.4로 설정했지만, Vector의 성능이 낮아 BM25의 강점을 충분히 활용하지 못함.

**RRF 방식의 상대적 우수성:**

- Hybrid RRF(Recall@1 80%)가 Hybrid Weighted(70%)보다 우수함.
- RRF는 순위 기반이므로 점수 스케일 차이의 영향을 덜 받음.
- 하지만 여전히 BM25 단독(92%)보다는 낮음.

#### 2.3.3 실패 분석 (Failure Analysis)

**Vector Only가 예상보다 낮은 성능을 보인 이유:**

1. **한국사 도메인의 특성:**
   - 한국사 질문은 대부분 **고유명사(인물명, 사건명, 서적명)** 중심임.
   - 예: "세종대왕", "임진왜란", "조선왕조실록" 등
   - 이러한 고유명사는 **정확한 키워드 매칭**이 의미적 유사도보다 중요함.

2. **임베딩 모델의 한계:**
   - `bge-m3`는 다국어 모델이지만, 한국사 고유명사에 대한 특화 학습이 부족할 수 있음.
   - 특히 한자어 고유명사는 임베딩 공간에서 유사도가 낮게 계산될 수 있음.

3. **질문 유형:**
   - 평가 데이터셋의 질문이 대부분 **사실 확인(Fact)** 유형임.
   - "누가", "언제", "무엇" 같은 명확한 키워드가 포함된 질문이 많음.
   - 이러한 질문에는 BM25가 Vector보다 유리함.

#### 2.3.4 LLM 재평가 (LLM-as-a-Judge Verification)

**검증 목적:** ID 매칭 실패가 진짜 실패인지, 아니면 의미적으로는 정답인데 ID만 다른 케이스인지 확인하기 위해 LLM(Gemini)을 심판으로 사용하여 재평가를 수행했습니다.

**검증 방법:**
- Vector Only에서 Recall@1 실패한 17개 케이스를 추출
- 각 케이스의 Top-1 검색 결과를 LLM에게 제공
- LLM이 "이 텍스트만으로 질문에 답할 수 있는가?"를 판단

**검증 결과 (2025-11-22 13:30:53):**

| 지표 | 값 |
| :--- | :---: |
| 원본 Recall@1 | 66.0% (실패: 17개) |
| 보정 Recall@1 | 72.0% (실제 실패: 14개) |
| 개선 폭 | +6.0%p |
| 의미적 정답 (Semantic Match) | 3개 |
| 진짜 실패 (True Failure) | 14개 |

**주요 발견 사항:**

1. **의미적 정답 케이스 (3개):**
   - 예: "이성계가 우왕과 최영에게 보낸 서신" 질문에서, 정답 ID는 `chk_000502`였지만 Vector가 찾은 `chk_000503`도 동일한 서신 내용을 포함하여 질문에 답할 수 있었음.
   - 이는 **중복 청크(Duplicate Content)** 문제로, Vector는 실제로 관련 문서를 잘 찾았지만 ID가 달라서 실패로 처리됨.

2. **진짜 실패 케이스 (14개):**
   - 대부분의 실패는 **진짜 실패**였음.
   - 예: "묘청과 정지상이 서경으로의 천도" 질문에서, Vector가 찾은 문서는 서경의 풍수지리적 이점에 대한 일반적 언급만 있고, 구체적인 "풍수지리적 관점"과 "지리적 이점"을 각각 서술하지 못함.

**결론:**
- 보정 후에도 Recall@1이 72%로 여전히 BM25(92%)보다 **20%p 낮음**.
- ID 매칭 실패의 대부분(14/17 = 82%)이 진짜 실패였음.
- Vector 모델(bge-m3)이 한국사 고유명사 학습이 부족하거나, 한국사 도메인 특성상 키워드 매칭이 더 중요하다는 것이 확인됨.
- **BM25 선택이 확실히 옳았음**을 데이터로 증명함.

**Hybrid 방식이 BM25보다 성능이 낮은 이유:**

**핵심 원인: 임베딩 모델(BGE-m3) 성능 부족**

1. **Vector의 낮은 성능이 하이브리드를 끌어내림:**
   - Vector Only의 Recall@1이 66%로 낮음
   - 하이브리드 점수 계산: `Hybrid Score = 0.6 × Vector_Score + 0.4 × BM25_Score`
   - Vector가 틀린 케이스에서 BM25가 맞았어도, Vector의 낮은 점수(0.6 가중치)로 인해 하이브리드 점수가 떨어짐
   - **결과:** BM25의 강점(92%)을 Vector의 약점(66%)이 상쇄시킴

2. **수학적 분석:**
   - Hybrid (Weighted): 70% = Vector(66%)의 60% + BM25(92%)의 40% 효과
   - Hybrid (RRF): 80% = 순위 기반이므로 점수 스케일 차이에 덜 민감하지만, 여전히 Vector의 낮은 순위가 영향을 미침
   - **결론:** Vector 성능이 낮으면 하이브리드도 낮아짐

3. **점수 정규화의 한계:**
   - Min-Max 정규화는 두 점수의 분포가 다를 때 공정한 결합이 어려움
   - Vector 점수는 대부분 0.3~0.8 범위에 몰려있고, BM25 점수는 0~20+ 범위로 넓게 분포함

4. **가중치 설정:**
   - Vector 0.6, BM25 0.4는 일반적인 RAG에서 사용되지만, 한국사 도메인에서는 BM25 비중을 더 높여야 할 수도 있음
   - 하지만 Vector 성능이 66%로 낮으면, 가중치를 조정해도 근본적 해결이 어려움

**시나리오 분석:**
- **현재 (Vector 66%):** BM25 92% > Hybrid 70-80% > Vector 66%
- **Vector 85% 가정:** BM25 92% ≈ Hybrid 88-90% > Vector 85%
- **Vector 95% 가정:** Hybrid 93-95% > BM25 92% > Vector 95%

**결론:** 현재는 **임베딩 모델 성능이 낮아서** 하이브리드 검색이 BM25 단독보다 성능이 떨어짐. Vector 성능을 개선하면 하이브리드의 잠재력이 발휘될 수 있음.

---

### 2.4 의사결정 (Conclusion & Pivot)

#### 2.4.1 최종 선택

**BM25 Only (Okt 형태소 분석기)**를 최종 검색 전략으로 선정.

#### 2.4.2 선정 근거 (Adoption Rationale)

1. **압도적인 Recall@1 (92%):**
   - 사용자가 원하는 정보가 검색 결과 최상단에 위치할 확률이 가장 높음.
   - Vector Only(66%)보다 **26%p** 높은 성능.
   - Hybrid 방식들보다도 우수함.

2. **높은 Recall@5 (98%):**
   - Reranker에게 넘겨줄 후보군 품질이 가장 우수함.
   - 50개 샘플 중 49개가 상위 5개 안에 포함됨.

3. **높은 MRR (0.947):**
   - 정답이 평균적으로 매우 상위에 위치함.
   - Vector Only(0.760)보다 약 **25%** 높음.

4. **적절한 검색 속도 (31.2ms):**
   - 실시간 검색 서비스에 충분히 빠른 속도.
   - Hybrid Weighted(76.0ms)보다 약 **2.4배** 빠름.

5. **한국사 도메인 특성에 최적:**
   - 한국사 질문은 고유명사 중심이므로, 키워드 매칭이 의미적 유사도보다 중요함.
   - BM25가 이러한 특성에 가장 적합함.

#### 2.4.3 Pivot (계획 변경)

**초기 계획:**
- 하이브리드 검색(Vector + BM25)이 단독 검색보다 우수할 것으로 예상했음 (가설 3, 4).
- Vector가 맥락 질문에 강하고, BM25가 키워드 질문에 강하므로, 두 방식을 결합하면 모든 질문 유형을 커버할 수 있을 것으로 예상했음.

**실제 결과:**
- **BM25 Only가 모든 지표에서 1위**를 차지함.
- Vector Only는 예상보다 낮은 성능(Recall@1 66%)을 보임.
- Hybrid 방식은 BM25 단독보다 성능이 낮았음.

**결정:**
- 예상과 달리 **BM25 Only가 가장 우수한 성능**을 보여주었으므로, BM25 Only를 최종 검색 전략으로 선정.
- 이는 **데이터 기반 의사결정(Data-Driven Decision)**의 좋은 사례임.
- "하이브리드 검색을 썼다"는 사실보다, **"실제 데이터로 검증하여 가장 좋은 방식을 선택했다"**는 것이 더 중요함.

#### 2.4.4 향후 개선 방향

1. **Vector 검색 개선:**
   - 한국사 도메인에 특화된 임베딩 모델 파인튜닝 고려.
   - 또는 한국어 역사 용어에 강한 모델 탐색.

2. **하이브리드 검색 재검토:**
   - Vector 성능이 개선되면, 하이브리드 검색의 효과를 재평가.
   - 가중치 튜닝 (예: Vector 0.3, BM25 0.7) 실험.

3. **질문 유형별 분기:**
   - 키워드 질문: BM25 사용.
   - 맥락 질문: Vector 또는 Hybrid 사용.
   - 질문 분류 모델을 통해 자동으로 전략 선택.

#### 2.4.5 구현 반영

- `hybrid_retriever.py`는 이미 구현되어 있으나, **기본 검색 전략을 BM25 Only로 설정**.
- 코드 위치: `05_Retrieval_Optimization/hybrid_retriever.py`
- 사용 방법: `retriever.search_bm25_only(query, top_k=10)` 또는 `retriever.search()`에서 `use_rrf=False`, `vector_weight=0.0`, `bm25_weight=1.0`으로 설정.

---

### 2.5 면접 대비 포인트 (Key Takeaway)

이 실험을 통해 면접에서 다음과 같이 설명할 수 있습니다:

> "처음엔 하이브리드 검색을 도입하려 했으나, 한국사 데이터 특성상 키워드 매칭이 중요하다고 판단하여 **Vector, BM25, Weighted Hybrid, RRF 4가지를 비교 실험**했습니다.
> 
> 실험 결과, **BM25 Only가 Recall@1 92%, Recall@5 98%로 가장 높은 성능**을 보여 이를 채택했습니다. 이는 한국사 질문이 고유명사 중심이라는 도메인 특성 때문으로 분석됩니다.
> 
> 예상과 달리 하이브리드 검색이 단독 검색보다 성능이 낮았는데, 이는 Vector의 낮은 성능(Recall@1 66%)이 하이브리드 점수를 끌어내린 것으로 보입니다.
> 
> **추가로 LLM-as-a-Judge 방식으로 재검증**을 수행했는데, Vector의 실패 케이스 17개 중 14개(82%)가 진짜 실패였고, 보정 후에도 Recall@1이 72%로 여전히 BM25보다 낮았습니다. 이를 통해 **BM25 선택이 확실히 옳았음**을 데이터로 증명했습니다."

---

## 3. 하이브리드 리트리버 구현 (완료)

- `hybrid_retriever.py` 구현 완료
- Vector Search (ChromaDB + BGE-m3) + BM25 Search (rank_bm25 + Okt) 결합
- 가중치 결합 및 RRF 방식 모두 지원

---

## 4. Reranker 구현 및 검증

### 4.1 가설 (Hypothesis)

BM25가 Recall@5 98%로 후보군을 잘 찾아주지만, **정답이 1위에 오는 비율(Recall@1)은 92%**입니다. Reranker(Cross-Encoder)를 추가하면, **문맥을 깊이 분석하여 정답을 1위로 올려줄 수 있을 것**으로 예상했습니다.

- **가설:** BM25 + Reranker 조합이 BM25 Only보다 Recall@1과 MRR이 더 높을 것이다.
- **예상:** Recall@1이 92% → 95% 이상으로 향상될 것으로 예상.

---

### 4.2 실험 설계 (Experiment Design)

#### 4.2.1 목적
Reranker를 추가하여 최종 검색 정확도를 향상시킬 수 있는지 검증.

#### 4.2.2 모델 선정
- **모델:** `BAAI/bge-reranker-v2-m3` (Cross-Encoder)
- **선정 이유:** 최신 다국어 SOTA 리랭커, 한국어 지원

#### 4.2.3 실험 규모
- 평가 데이터: 50개 샘플 (기존 벤치마크와 동일)
- 1차 검색: BM25 (Top-50 후보군 확보)
- 2차 정렬: Reranker (Top-5 최종 결과)

#### 4.2.4 평가 지표
- Recall@1, Recall@3, Recall@5, MRR, 평균 검색 시간

---

### 4.3 검증 결과 (Validation)

**실험 일시:** 2025-11-22 14:10:40

| Strategy | Recall@1 | Recall@3 | Recall@5 | MRR | Avg Time (ms) |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **BM25 Only** | **92.0%** | **98.0%** | **98.0%** | **0.947** | **31.0ms** |
| **BM25 + Reranker** | 90.0% | 96.0% | 98.0% | 0.924 | 269.1ms |

**주요 발견:**
- **예상과 달리 Reranker 추가 시 성능이 약간 하락** (Recall@1: 92% → 90%, -2%p)
- **검색 시간이 약 8.7배 증가** (31ms → 269ms)
- **Recall@5는 동일** (98%)

---

### 4.4 실패 분석 (Failure Analysis)

**Reranker가 성능을 떨어뜨린 이유:**

1. **한국사 도메인의 특수성:**
   - 한국사 질문은 **고유명사(인물명, 사건명) 중심**으로, 키워드 매칭이 매우 중요함.
   - BM25가 이미 키워드로 정확히 찾은 문서를, Reranker가 문맥 분석을 통해 다른 문서로 바꿔버린 경우 발생.

2. **Reranker의 한계:**
   - Cross-Encoder는 Query-Document 쌍을 함께 분석하지만, **한국어 고유명사에 대한 학습이 부족**할 수 있음.
   - 의미적으로는 관련 있어 보이지만, 실제로는 정답이 아닌 문서를 더 높은 점수로 평가할 수 있음.

3. **후보군 크기:**
   - Top-50 후보군에서 Reranker가 선택했지만, 정답이 Top-50 밖에 있었을 가능성은 낮음 (BM25 Recall@50은 거의 100%).

---

### 4.5 의사결정 (Conclusion & Pivot)

#### 4.5.1 최종 선택

**BM25 Only를 유지** (Reranker 미사용)

#### 4.5.2 선정 근거

1. **성능 우수성:**
   - Recall@1 92%로 이미 매우 높은 성능
   - Reranker 추가 시 오히려 2%p 하락

2. **검색 속도:**
   - BM25 Only: 31ms (실시간 검색에 적합)
   - BM25 + Reranker: 269ms (약 8.7배 느림)

3. **도메인 특성:**
   - 한국사는 키워드 매칭이 의미 분석보다 중요
   - BM25가 이미 최적의 성능을 보여줌

#### 4.5.3 Pivot (계획 변경)

**초기 계획:**
- Reranker를 추가하여 Recall@1을 95% 이상으로 향상시킬 것으로 예상

**실제 결과:**
- Reranker 추가 시 오히려 성능이 하락 (92% → 90%)
- 검색 시간이 크게 증가 (31ms → 269ms)

**결정:**
- **"Reranker를 무조건 쓰는 게 좋은 게 아니다"**는 것을 데이터로 증명
- 현재 도메인(한국사)에서는 **BM25 단독이 최선**
- 향후 다른 도메인(예: 의학, 법률 등 문맥이 중요한 분야)에서는 Reranker 효과를 재검토

---

## 5. 최종 검색 전략 확정

### 5.1 최종 아키텍처

```
[사용자 쿼리]
     ↓
[BM25 검색 (Okt 형태소 분석)]
     ↓
[Top-K 결과 반환]
```

### 5.2 최종 성능

- **Recall@1:** 92.0%
- **Recall@5:** 98.0%
- **MRR:** 0.947
- **평균 검색 시간:** 31.0ms

### 5.3 핵심 교훈

1. **"하이브리드 검색이 항상 좋은 것은 아니다"** - Vector 성능이 낮으면 하이브리드도 낮아짐
2. **"Reranker가 항상 성능을 올리는 것은 아니다"** - 도메인 특성에 따라 오히려 성능이 하락할 수 있음
3. **"데이터 기반 의사결정이 중요하다"** - 이론보다 실제 벤치마크 결과를 신뢰

---

## 6. 최종 결론 (Final Conclusion)

### 6.1 최종 선택과 채택 근거

**최종 검색 전략: BM25 Only (Okt 형태소 분석기)**

**채택 근거:**

1. **압도적인 성능 지표:**
   - Recall@1: 92.0% (Vector Only 66%보다 26%p 높음)
   - Recall@5: 98.0% (50개 샘플 중 49개 성공)
   - MRR: 0.947 (Vector Only 0.760보다 약 25% 높음)
   - 평균 검색 시간: 31.0ms (실시간 서비스에 적합)

2. **도메인 특성에 최적화:**
   - 한국사 질문은 고유명사(인물명, 사건명, 서적명) 중심
   - 키워드 매칭이 의미적 유사도보다 중요함
   - BM25가 이러한 특성에 가장 적합함

3. **데이터 기반 의사결정:**
   - 하이브리드 검색, Reranker 등 다양한 방법을 실험했으나, BM25 단독이 가장 우수
   - "하이브리드 검색을 썼다"는 사실보다, "실제 데이터로 검증하여 가장 좋은 방식을 선택했다"는 것이 더 중요함

4. **비용 효율성:**
   - Reranker 미사용으로 검색 시간 8.7배 단축 (269ms → 31ms)
   - Vector 검색 불필요로 임베딩 모델 로딩 비용 절감

### 6.2 핵심 교훈 (Key Takeaways)

1. **"하이브리드 검색이 항상 좋은 것은 아니다"**
   - Vector 성능이 낮으면(Recall@1 66%) 하이브리드도 낮아짐
   - BM25의 강점(92%)을 Vector의 약점(66%)이 상쇄시킴

2. **"Reranker가 항상 성능을 올리는 것은 아니다"**
   - 도메인 특성에 따라 오히려 성능이 하락할 수 있음 (92% → 90%)
   - 검색 시간이 크게 증가하나(31ms → 269ms) 성능 향상은 없음

3. **"데이터 기반 의사결정이 중요하다"**
   - 이론이나 일반적인 베스트 프랙티스보다 실제 벤치마크 결과를 신뢰
   - LLM-as-a-Judge 등 추가 검증 방법으로 신뢰성 확보

### 6.3 향후 개선 방향

1. **Vector 검색 개선:**
   - 한국사 도메인에 특화된 임베딩 모델 파인튜닝 고려
   - Vector 성능이 개선되면 하이브리드 검색의 효과를 재평가

2. **질문 유형별 분기:**
   - 키워드 질문: BM25 사용 (현재 전략)
   - 맥락 질문: Vector 또는 Hybrid 사용
   - 질문 분류 모델을 통해 자동으로 전략 선택

3. **Reranker 재검토:**
   - 다른 도메인(의학, 법률 등 문맥이 중요한 분야)에서는 Reranker 효과를 재검토
   - 한국어 특화 Reranker 모델 탐색

---

## 7. 참고 자료

### 7.1 벤치마크 결과 파일
- `tokenizer_benchmark_result.md`: 형태소 분석기 벤치마크 결과
- `retrieval_benchmark_result.md`: 검색 전략 벤치마크 결과
- `reranker_benchmark_result.md`: Reranker 벤치마크 결과
- `vector_failure_verification_report.md`: Vector 실패 케이스 LLM 재평가 결과

### 7.2 구현 코드
- `hybrid_retriever.py`: 하이브리드 리트리버 구현
- `reranker.py`: Reranker 구현 (참고용, 현재 미사용)
- `retrieval_system.py`: 통합 검색 시스템 (참고용)

### 7.3 평가 데이터셋
- `03_Embedding/data/korean_history_benchmark_2000.json`: 2000개 질문-답변 쌍

### 7.4 관련 문서
- `SPEC_Retrieval_Strategy.md`: 검색 전략 기술 명세서
- `README_Embedding_Log.md`: 임베딩 모델 선정 과정

