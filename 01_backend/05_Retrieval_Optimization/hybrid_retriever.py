"""
í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ (Hybrid Retriever)
- Vector Search (ChromaDB) + BM25 (Keyword Search) ê²°í•©
- í˜•íƒœì†Œ ë¶„ì„ê¸°: Okt (ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ 92.0% Recall@1)
- ê°€ì¤‘ì¹˜: Vector 0.6, BM25 0.4
- RRF (Reciprocal Rank Fusion) ì˜µì…˜ ì§€ì›
"""
import json
import time
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

import chromadb
from chromadb.config import Settings
import torch
from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi
from konlpy.tag import Okt

# -----------------------------------------------------------------------------
# ì„¤ì •
# -----------------------------------------------------------------------------
BASE_DIR = Path("/home/pencilfoxs/Hackathon/4_History_Docent")
VECTORDB_DIR = BASE_DIR / "04_VectorDB/chroma_db"
COLLECTION_NAME = "korean_history_chunks"
EMBEDDING_MODEL = "BAAI/bge-m3"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
VECTOR_WEIGHT = 0.6
BM25_WEIGHT = 0.4

# RRF íŒŒë¼ë¯¸í„°
RRF_K = 60  # RRF ìƒìˆ˜ (ì¼ë°˜ì ìœ¼ë¡œ 60 ì‚¬ìš©)

# -----------------------------------------------------------------------------
# ë°ì´í„° í´ë˜ìŠ¤
# -----------------------------------------------------------------------------
@dataclass
class RetrievalResult:
    """ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    chunk_id: str
    text: str
    metadata: Dict[str, Any]
    vector_score: float
    bm25_score: float
    hybrid_score: float
    rank: int

# -----------------------------------------------------------------------------
# í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ í´ë˜ìŠ¤
# -----------------------------------------------------------------------------
class HybridRetriever:
    """í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„: Vector + BM25"""
    
    def __init__(
        self,
        vectordb_path: Path = VECTORDB_DIR,
        collection_name: str = COLLECTION_NAME,
        embedding_model: str = EMBEDDING_MODEL,
        device: str = DEVICE,
        vector_weight: float = VECTOR_WEIGHT,
        bm25_weight: float = BM25_WEIGHT,
        use_rrf: bool = False
    ):
        """
        Args:
            vectordb_path: ChromaDB ê²½ë¡œ
            collection_name: Collection ì´ë¦„
            embedding_model: ì„ë² ë”© ëª¨ë¸ ì´ë¦„
            device: ë””ë°”ì´ìŠ¤ (cuda/cpu)
            vector_weight: Vector ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.6)
            bm25_weight: BM25 ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.4)
            use_rrf: RRF ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ False)
        """
        self.vectordb_path = vectordb_path
        self.collection_name = collection_name
        self.embedding_model_name = embedding_model
        self.device = device
        self.vector_weight = vector_weight
        self.bm25_weight = bm25_weight
        self.use_rrf = use_rrf
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.client = None
        self.collection = None
        self.embedding_model = None
        self.tokenizer = None
        self.bm25_index = None
        self.documents = []
        self.doc_ids = []
        self.doc_metadata = []
        
        print(f"âœ… HybridRetriever ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - Vector ê°€ì¤‘ì¹˜: {vector_weight}")
        print(f"   - BM25 ê°€ì¤‘ì¹˜: {bm25_weight}")
        print(f"   - RRF ì‚¬ìš©: {use_rrf}")
    
    def initialize(self):
        """ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” (ChromaDB ì—°ê²°, ëª¨ë¸ ë¡œë“œ, BM25 ì¸ë±ìŠ¤ êµ¬ì¶•)"""
        print("\nğŸš€ HybridRetriever ì´ˆê¸°í™” ì‹œì‘...")
        
        # 1. ChromaDB ì—°ê²°
        print("   ğŸ“‚ ChromaDB ì—°ê²° ì¤‘...")
        self.client = chromadb.PersistentClient(
            path=str(self.vectordb_path),
            settings=Settings(anonymized_telemetry=False)
        )
        self.collection = self.client.get_collection(name=self.collection_name)
        print(f"   âœ… ChromaDB ì—°ê²° ì™„ë£Œ (Collection: {self.collection_name})")
        
        # 2. ì „ì²´ ë¬¸ì„œ ë¡œë“œ
        print("   ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
        all_data = self.collection.get()
        self.documents = all_data['documents']
        self.doc_ids = all_data['ids']
        self.doc_metadata = all_data['metadatas']
        print(f"   âœ… ë¬¸ì„œ {len(self.documents)}ê°œ ë¡œë“œ ì™„ë£Œ")
        
        # 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print(f"   ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {self.embedding_model_name} ({self.device})...")
        self.embedding_model = SentenceTransformer(
            self.embedding_model_name,
            device=self.device
        )
        print("   âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # 4. í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” (Okt)
        print("   ğŸ”¤ í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘ (Okt)...")
        self.tokenizer = Okt()
        print("   âœ… í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        # 5. BM25 ì¸ë±ìŠ¤ êµ¬ì¶•
        print("   ğŸ§® BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        start_time = time.time()
        tokenized_corpus = []
        for doc in self.documents:
            tokens = self.tokenizer.morphs(doc, stem=True)
            tokenized_corpus.append([t for t in tokens if t.strip()])
        
        self.bm25_index = BM25Okapi(tokenized_corpus)
        indexing_time = time.time() - start_time
        print(f"   âœ… BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ ({indexing_time:.2f}ì´ˆ)")
        
        print("\nâœ… HybridRetriever ì´ˆê¸°í™” ì™„ë£Œ!\n")
    
    def _normalize_scores(self, scores: np.ndarray) -> np.ndarray:
        """ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (Min-Max Normalization)"""
        if len(scores) == 0:
            return scores
        min_score = scores.min()
        max_score = scores.max()
        if max_score == min_score:
            return np.ones_like(scores)
        return (scores - min_score) / (max_score - min_score)
    
    def _apply_rrf(self, vector_ranks: Dict[str, int], bm25_ranks: Dict[str, int]) -> Dict[str, float]:
        """Reciprocal Rank Fusion (RRF) ì ìš©"""
        rrf_scores = {}
        all_ids = set(vector_ranks.keys()) | set(bm25_ranks.keys())
        
        for doc_id in all_ids:
            score = 0.0
            if doc_id in vector_ranks:
                score += 1.0 / (RRF_K + vector_ranks[doc_id])
            if doc_id in bm25_ranks:
                score += 1.0 / (RRF_K + bm25_ranks[doc_id])
            rrf_scores[doc_id] = score
        
        return rrf_scores
    
    def search(
        self,
        query: str,
        top_k: int = 10,
        return_scores: bool = False
    ) -> List[RetrievalResult]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ Kê°œ ê²°ê³¼
            return_scores: ì ìˆ˜ ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (RetrievalResult)
        """
        if self.bm25_index is None:
            raise ValueError("ë¦¬íŠ¸ë¦¬ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # 1. Vector ê²€ìƒ‰
        query_embedding = self.embedding_model.encode(
            query,
            normalize_embeddings=True
        ).tolist()
        
        vector_results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k * 2  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        )
        
        # Vector ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        vector_scores = {}
        vector_ranks = {}
        for i, doc_id in enumerate(vector_results['ids'][0]):
            # ChromaDBëŠ” ê±°ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ, ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            # ê±°ë¦¬ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜ (1 / (1 + distance))
            distance = 1.0 - vector_results['distances'][0][i]  # cosine similarity
            vector_scores[doc_id] = distance
            vector_ranks[doc_id] = i + 1
        
        # 2. BM25 ê²€ìƒ‰
        tokenized_query = self.tokenizer.morphs(query, stem=True)
        tokenized_query = [t for t in tokenized_query if t.strip()]
        
        bm25_scores_array = self.bm25_index.get_scores(tokenized_query)
        bm25_scores = {}
        bm25_ranks = {}
        
        # ìƒìœ„ ê²°ê³¼ë§Œ ì¶”ì¶œ
        top_bm25_indices = np.argsort(bm25_scores_array)[::-1][:top_k * 2]
        for rank, idx in enumerate(top_bm25_indices):
            doc_id = self.doc_ids[idx]
            bm25_scores[doc_id] = float(bm25_scores_array[idx])
            bm25_ranks[doc_id] = rank + 1
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        if self.use_rrf:
            # RRF ë°©ì‹
            hybrid_scores = self._apply_rrf(vector_ranks, bm25_ranks)
        else:
            # ê°€ì¤‘ì¹˜ ê²°í•© ë°©ì‹
            all_ids = set(vector_scores.keys()) | set(bm25_scores.keys())
            hybrid_scores = {}
            
            # ì ìˆ˜ ì •ê·œí™”
            if vector_scores:
                vector_values = np.array([vector_scores.get(doc_id, 0) for doc_id in all_ids])
                vector_normalized = self._normalize_scores(vector_values)
            else:
                vector_normalized = np.zeros(len(all_ids))
            
            if bm25_scores:
                bm25_values = np.array([bm25_scores.get(doc_id, 0) for doc_id in all_ids])
                bm25_normalized = self._normalize_scores(bm25_values)
            else:
                bm25_normalized = np.zeros(len(all_ids))
            
            # ê°€ì¤‘ì¹˜ ê²°í•©
            for i, doc_id in enumerate(all_ids):
                hybrid_scores[doc_id] = (
                    self.vector_weight * vector_normalized[i] +
                    self.bm25_weight * bm25_normalized[i]
                )
        
        # 4. ìƒìœ„ Kê°œ ê²°ê³¼ ì¶”ì¶œ
        sorted_results = sorted(
            hybrid_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )[:top_k]
        
        # 5. ê²°ê³¼ êµ¬ì„±
        results = []
        for rank, (doc_id, hybrid_score) in enumerate(sorted_results, 1):
            # ë¬¸ì„œ ì¸ë±ìŠ¤ ì°¾ê¸°
            doc_idx = self.doc_ids.index(doc_id)
            
            result = RetrievalResult(
                chunk_id=doc_id,
                text=self.documents[doc_idx],
                metadata=self.doc_metadata[doc_idx] if self.doc_metadata else {},
                vector_score=vector_scores.get(doc_id, 0.0),
                bm25_score=bm25_scores.get(doc_id, 0.0),
                hybrid_score=hybrid_score,
                rank=rank
            )
            results.append(result)
        
        return results
    
    def search_vector_only(self, query: str, top_k: int = 10) -> List[RetrievalResult]:
        """Vector ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (ë¹„êµìš©)"""
        query_embedding = self.embedding_model.encode(
            query,
            normalize_embeddings=True
        ).tolist()
        
        vector_results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )
        
        results = []
        for i, doc_id in enumerate(vector_results['ids'][0]):
            doc_idx = self.doc_ids.index(doc_id)
            distance = 1.0 - vector_results['distances'][0][i]
            
            result = RetrievalResult(
                chunk_id=doc_id,
                text=self.documents[doc_idx],
                metadata=self.doc_metadata[doc_idx] if self.doc_metadata else {},
                vector_score=distance,
                bm25_score=0.0,
                hybrid_score=distance,
                rank=i + 1
            )
            results.append(result)
        
        return results
    
    def search_bm25_only(self, query: str, top_k: int = 10) -> List[RetrievalResult]:
        """BM25 ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (ë¹„êµìš©)"""
        tokenized_query = self.tokenizer.morphs(query, stem=True)
        tokenized_query = [t for t in tokenized_query if t.strip()]
        
        bm25_scores_array = self.bm25_index.get_scores(tokenized_query)
        top_indices = np.argsort(bm25_scores_array)[::-1][:top_k]
        
        results = []
        for rank, idx in enumerate(top_indices, 1):
            result = RetrievalResult(
                chunk_id=self.doc_ids[idx],
                text=self.documents[idx],
                metadata=self.doc_metadata[idx] if self.doc_metadata else {},
                vector_score=0.0,
                bm25_score=float(bm25_scores_array[idx]),
                hybrid_score=float(bm25_scores_array[idx]),
                rank=rank
            )
            results.append(result)
        
        return results

# -----------------------------------------------------------------------------
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    # ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
    retriever = HybridRetriever(
        vector_weight=0.6,
        bm25_weight=0.4,
        use_rrf=False
    )
    retriever.initialize()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ì„¸ì¢…ëŒ€ì™•ì´ ë§Œë“  í•œê¸€",
        "ì„ì§„ì™œë€",
        "ì¡°ì„ ì™•ì¡°ì‹¤ë¡",
        "ì •ì•½ìš©ì˜ ì‹¤í•™",
        "ê³ ë ¤ì‹œëŒ€ ë¬´ì—­"
    ]
    
    print("=" * 60)
    print("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for query in test_queries:
        print(f"\nğŸ” ì¿¼ë¦¬: {query}")
        print("-" * 60)
        
        results = retriever.search(query, top_k=3)
        
        for result in results:
            print(f"\n[Rank {result.rank}] {result.chunk_id}")
            print(f"  Vector Score: {result.vector_score:.4f}")
            print(f"  BM25 Score: {result.bm25_score:.4f}")
            print(f"  Hybrid Score: {result.hybrid_score:.4f}")
            print(f"  Text: {result.text[:100]}...")
            print(f"  Metadata: {result.metadata}")

