"""
[Vector ê²€ìƒ‰ ì‹¤íŒ¨ ì›ì¸ ì‹¬ì¸µ ë¶„ì„ - LLM-as-a-Judge]
- ëª©ì : ID ë§¤ì¹­ ì‹¤íŒ¨ê°€ ì§„ì§œ ì‹¤íŒ¨ì¸ì§€, ìœ ì‚¬ ì •ë‹µ(Semantic Match)ì¸ì§€ LLMìœ¼ë¡œ íŒë³„
- ëŒ€ìƒ: Vector Only ì „ëµì—ì„œ ì‹¤íŒ¨í•œ(Recall@1=0) ì¼€ì´ìŠ¤ë“¤
- ë°©ë²•: Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨
"""
import json
import time
import requests
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Any
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv("/home/pencilfoxs/00_new/.env2")

# -----------------------------------------------------------------------------
# ì„¤ì •
# -----------------------------------------------------------------------------
BASE_DIR = Path("/home/pencilfoxs/00_new/History_Docent")
BENCHMARK_DATA = BASE_DIR / "03_Embedding/data/korean_history_benchmark_2000.json"
BENCHMARK_RESULT = BASE_DIR / "05_Retrieval_Optimization/retrieval_benchmark_result.md"
OUTPUT_REPORT = BASE_DIR / "05_Retrieval_Optimization/vector_failure_verification_report.md"

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent"

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent))
from hybrid_retriever import HybridRetriever

# -----------------------------------------------------------------------------
# LLM íŒì • í•¨ìˆ˜
# -----------------------------------------------------------------------------
def evaluate_with_llm(query: str, retrieved_text: str, max_retries: int = 3) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨
    
    Returns:
        {
            "can_answer": bool,  # ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ”ê°€?
            "confidence": str,   # "HIGH", "MEDIUM", "LOW"
            "reasoning": str,    # íŒë‹¨ ê·¼ê±°
            "raw_response": str # LLM ì›ë³¸ ì‘ë‹µ
        }
    """
    prompt = f"""ë‹¹ì‹ ì€ ì—„ê²©í•œ í‰ê°€ìì…ë‹ˆë‹¤. ì•„ë˜ [ì œê³µëœ í…ìŠ¤íŠ¸]ê°€ [ì§ˆë¬¸]ì— ëŒ€í•œ ëª…í™•í•˜ê³  ì¶©ë¶„í•œ ì •ë‹µì„ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

[ì§ˆë¬¸]: {query}

[ì œê³µëœ í…ìŠ¤íŠ¸]: {retrieved_text[:2000]}  # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„

**íŒë‹¨ ê¸°ì¤€:**
1. ì œê³µëœ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ í•  ìˆ˜ ìˆëŠ”ê°€?
2. ë‹µì´ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ê°€? (ëª¨í˜¸í•˜ê±°ë‚˜ ì¶”ì¸¡ì„± ë‹µë³€ì€ NO)
3. ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë‚˜ ê°œë…ì´ í…ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?

**ì‘ë‹µ í˜•ì‹ (JSON):**
{{
    "can_answer": true/false,
    "confidence": "HIGH"/"MEDIUM"/"LOW",
    "reasoning": "íŒë‹¨ ê·¼ê±°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…"
}}

YES ë˜ëŠ” NOë§Œ ë‹µí•˜ì§€ ë§ê³ , ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”."""

    payload = {
        "contents": [{
            "parts": [{
                "text": prompt
            }]
        }],
        "generationConfig": {
            "temperature": 0.1,  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± í™•ë³´
            "maxOutputTokens": 200
        }
    }
    
    headers = {
        "Content-Type": "application/json"
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                f"{GEMINI_API_URL}?key={GOOGLE_API_KEY}",
                json=payload,
                headers=headers,
                timeout=30
            )
            
            if response.status_code != 200:
                raise Exception(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text[:200]}")
            
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                text_response = result['candidates'][0]['content']['parts'][0]['text'].strip()
                
                # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
                if text_response.startswith("```"):
                    text_response = text_response.replace("```json", "").replace("```", "").strip()
                
                try:
                    llm_result = json.loads(text_response)
                    return {
                        "can_answer": llm_result.get("can_answer", False),
                        "confidence": llm_result.get("confidence", "LOW"),
                        "reasoning": llm_result.get("reasoning", ""),
                        "raw_response": text_response
                    }
                except json.JSONDecodeError:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
                    if "can_answer" in text_response.lower() or "true" in text_response.lower():
                        return {
                            "can_answer": True,
                            "confidence": "MEDIUM",
                            "reasoning": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì •",
                            "raw_response": text_response
                        }
                    else:
                        return {
                            "can_answer": False,
                            "confidence": "MEDIUM",
                            "reasoning": "LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì •",
                            "raw_response": text_response
                        }
            else:
                raise Exception(f"ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {result}")
                
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            else:
                return {
                    "can_answer": False,
                    "confidence": "LOW",
                    "reasoning": f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}",
                    "raw_response": ""
                }
    
    return {
        "can_answer": False,
        "confidence": "LOW",
        "reasoning": "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼",
        "raw_response": ""
    }

# -----------------------------------------------------------------------------
# ë©”ì¸ ë¡œì§
# -----------------------------------------------------------------------------
def main():
    print("=" * 60)
    print("Vector ê²€ìƒ‰ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ LLM ì¬í‰ê°€")
    print("=" * 60)
    
    # 1. ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì—ì„œ Vector Only ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ì¶”ì¶œ
    print("\nğŸ“‚ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¡œë“œ ì¤‘...")
    
    # ë²¤ì¹˜ë§ˆí¬ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ìˆ˜ì§‘
    retriever = HybridRetriever()
    retriever.initialize()
    
    with open(BENCHMARK_DATA, 'r', encoding='utf-8') as f:
        all_samples = json.load(f)
    
    import random
    random.seed(42)
    samples = random.sample(all_samples, min(50, len(all_samples)))
    
    print(f"   âœ… í‰ê°€ ë°ì´í„°: {len(samples)}ê°œ ìƒ˜í”Œ")
    
    # 2. Vector Only ê²€ìƒ‰ ì‹¤í–‰ ë° ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ìˆ˜ì§‘
    print("\nğŸ” Vector Only ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
    failure_cases = []
    
    for sample in tqdm(samples, desc="   ê²€ìƒ‰ ì¤‘"):
        query = sample['query']
        gold_id = sample['chunk_id']
        
        results = retriever.search_vector_only(query, top_k=5)
        
        # Recall@1 ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë§Œ ìˆ˜ì§‘
        if results and results[0].chunk_id != gold_id:
            failure_cases.append({
                "query": query,
                "gold_id": gold_id,
                "gold_text": sample.get('gold_text', ''),
                "retrieved_id": results[0].chunk_id,
                "retrieved_text": results[0].text,
                "retrieved_rank": 1
            })
    
    print(f"\n   ğŸ“Š Vector Only ì‹¤íŒ¨ ì¼€ì´ìŠ¤: {len(failure_cases)}ê°œ")
    
    if len(failure_cases) == 0:
        print("   âœ… ì‹¤íŒ¨ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. Vector ê²€ìƒ‰ì´ ì™„ë²½í•©ë‹ˆë‹¤!")
        return
    
    # 3. LLMìœ¼ë¡œ ê° ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ì¬í‰ê°€
    print(f"\nğŸ¤– LLM ì¬í‰ê°€ ì‹œì‘ (ì´ {len(failure_cases)}ê°œ)...")
    print("   âš ï¸  Gemini API í˜¸ì¶œë¡œ ì¸í•´ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
    
    verified_results = []
    semantic_matches = 0  # ì˜ë¯¸ì ìœ¼ë¡œëŠ” ì •ë‹µì¸ ì¼€ì´ìŠ¤
    
    for i, case in enumerate(tqdm(failure_cases, desc="   LLM í‰ê°€"), 1):
        query = case['query']
        retrieved_text = case['retrieved_text']
        
        # LLM íŒì •
        llm_result = evaluate_with_llm(query, retrieved_text)
        
        verified_results.append({
            **case,
            "llm_can_answer": llm_result["can_answer"],
            "llm_confidence": llm_result["confidence"],
            "llm_reasoning": llm_result["reasoning"],
            "llm_raw_response": llm_result["raw_response"]
        })
        
        if llm_result["can_answer"]:
            semantic_matches += 1
        
        # API Rate Limit ë°©ì§€
        time.sleep(0.5)
    
    # 4. ë³´ì •ëœ ì ìˆ˜ ê³„ì‚°
    original_failures = len(failure_cases)
    semantic_successes = semantic_matches
    corrected_failures = original_failures - semantic_successes
    
    original_recall_1 = ((50 - original_failures) / 50) * 100
    corrected_recall_1 = ((50 - corrected_failures) / 50) * 100
    improvement = corrected_recall_1 - original_recall_1
    
    # 5. ë¦¬í¬íŠ¸ ì‘ì„±
    print("\n" + "="*60)
    print("ğŸ“Š LLM ì¬í‰ê°€ ê²°ê³¼")
    print("="*60)
    print(f"\nì›ë³¸ Recall@1: {original_recall_1:.1f}% (ì‹¤íŒ¨: {original_failures}ê°œ)")
    print(f"ë³´ì • Recall@1: {corrected_recall_1:.1f}% (ì‹¤ì œ ì‹¤íŒ¨: {corrected_failures}ê°œ)")
    print(f"ê°œì„  í­: +{improvement:.1f}%p")
    print(f"\nì˜ë¯¸ì  ì •ë‹µ (Semantic Match): {semantic_successes}ê°œ")
    print(f"ì§„ì§œ ì‹¤íŒ¨ (True Failure): {corrected_failures}ê°œ")
    
    with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:
        f.write("# Vector ê²€ìƒ‰ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ LLM ì¬í‰ê°€ ë¦¬í¬íŠ¸\n\n")
        f.write(f"- í‰ê°€ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"- í‰ê°€ ëŒ€ìƒ: Vector Only ì‹¤íŒ¨ ì¼€ì´ìŠ¤ {len(failure_cases)}ê°œ\n\n")
        
        f.write("## ğŸ“Š ìš”ì•½ ê²°ê³¼\n\n")
        f.write(f"- **ì›ë³¸ Recall@1:** {original_recall_1:.1f}% (ì‹¤íŒ¨: {original_failures}ê°œ)\n")
        f.write(f"- **ë³´ì • Recall@1:** {corrected_recall_1:.1f}% (ì‹¤ì œ ì‹¤íŒ¨: {corrected_failures}ê°œ)\n")
        f.write(f"- **ê°œì„  í­:** +{improvement:.1f}%p\n")
        f.write(f"- **ì˜ë¯¸ì  ì •ë‹µ (Semantic Match):** {semantic_successes}ê°œ\n")
        f.write(f"- **ì§„ì§œ ì‹¤íŒ¨ (True Failure):** {corrected_failures}ê°œ\n\n")
        
        f.write("## ğŸ” ìƒì„¸ ë¶„ì„\n\n")
        
        # ì˜ë¯¸ì  ì •ë‹µ ì¼€ì´ìŠ¤
        f.write("### âœ… ì˜ë¯¸ì  ì •ë‹µ (Semantic Match) ì¼€ì´ìŠ¤\n\n")
        semantic_cases = [r for r in verified_results if r["llm_can_answer"]]
        for i, case in enumerate(semantic_cases[:10], 1):  # ìƒìœ„ 10ê°œë§Œ
            f.write(f"#### ì¼€ì´ìŠ¤ {i}\n")
            f.write(f"- **ì§ˆë¬¸:** {case['query']}\n")
            f.write(f"- **ì •ë‹µ ID:** {case['gold_id']}\n")
            f.write(f"- **ê²€ìƒ‰ëœ ID:** {case['retrieved_id']}\n")
            f.write(f"- **LLM íŒì •:** âœ… ë‹µë³€ ê°€ëŠ¥ (ì‹ ë¢°ë„: {case['llm_confidence']})\n")
            f.write(f"- **íŒë‹¨ ê·¼ê±°:** {case['llm_reasoning']}\n")
            f.write(f"- **ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ (ì¼ë¶€):** {case['retrieved_text'][:200]}...\n\n")
        
        # ì§„ì§œ ì‹¤íŒ¨ ì¼€ì´ìŠ¤
        f.write("### âŒ ì§„ì§œ ì‹¤íŒ¨ (True Failure) ì¼€ì´ìŠ¤\n\n")
        true_failures = [r for r in verified_results if not r["llm_can_answer"]]
        for i, case in enumerate(true_failures[:10], 1):  # ìƒìœ„ 10ê°œë§Œ
            f.write(f"#### ì¼€ì´ìŠ¤ {i}\n")
            f.write(f"- **ì§ˆë¬¸:** {case['query']}\n")
            f.write(f"- **ì •ë‹µ ID:** {case['gold_id']}\n")
            f.write(f"- **ê²€ìƒ‰ëœ ID:** {case['retrieved_id']}\n")
            f.write(f"- **LLM íŒì •:** âŒ ë‹µë³€ ë¶ˆê°€ (ì‹ ë¢°ë„: {case['llm_confidence']})\n")
            f.write(f"- **íŒë‹¨ ê·¼ê±°:** {case['llm_reasoning']}\n")
            f.write(f"- **ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ (ì¼ë¶€):** {case['retrieved_text'][:200]}...\n\n")
        
        # ê²°ë¡ 
        f.write("## ğŸ’¡ ê²°ë¡ \n\n")
        if corrected_recall_1 >= 85:
            f.write("**Vector ê²€ìƒ‰ì˜ ì‹¤ì œ ì„±ëŠ¥ì€ ë³´ì • í›„ 85% ì´ìƒìœ¼ë¡œ, ì¶©ë¶„íˆ ìš°ìˆ˜í•©ë‹ˆë‹¤.**\n\n")
            f.write("- ID ë§¤ì¹­ ì‹¤íŒ¨ì˜ ìƒë‹¹ ë¶€ë¶„ì´ 'ì˜ë¯¸ì  ì •ë‹µ'ì´ì—ˆìŒ\n")
            f.write("- Vector ê²€ìƒ‰ì€ ì‹¤ì œë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì˜ ì°¾ê³  ìˆìŒ\n")
            f.write("- í–¥í›„ Hybrid ê²€ìƒ‰ì˜ ì ì¬ë ¥ì€ ì—¬ì „íˆ ìœ íš¨í•  ìˆ˜ ìˆìŒ\n")
        else:
            f.write("**Vector ê²€ìƒ‰ì˜ ì‹¤ì œ ì„±ëŠ¥ë„ ë³´ì • í›„ì—ë„ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤.**\n\n")
            f.write("- ID ë§¤ì¹­ ì‹¤íŒ¨ì˜ ëŒ€ë¶€ë¶„ì´ 'ì§„ì§œ ì‹¤íŒ¨'ì˜€ìŒ\n")
            f.write("- Vector ëª¨ë¸(bge-m3)ì´ í•œêµ­ì‚¬ ê³ ìœ ëª…ì‚¬ í•™ìŠµì´ ë¶€ì¡±í•  ê°€ëŠ¥ì„±\n")
            f.write("- BM25 ì„ íƒì´ í™•ì‹¤íˆ ì˜³ì•˜ìŒ\n")
    
    print(f"\nğŸ’¾ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {OUTPUT_REPORT}")

if __name__ == "__main__":
    main()

