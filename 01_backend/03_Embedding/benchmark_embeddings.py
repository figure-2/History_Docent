import time
import json
import torch
import numpy as np
import pandas as pd
import requests
import os
from pathlib import Path
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# -----------------------------------------------------------------------------
# ì„¤ì • (Configuration)
# -----------------------------------------------------------------------------
DATA_DIR = Path("/home/pencilfoxs/00_new/History_Docent/03_Embedding/data")
# âœ… ìµœì¢… ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ 2000ê°œ ì‚¬ìš©
BENCHMARK_FILE = DATA_DIR / "korean_history_benchmark_2000.json"
RESULTS_DIR = Path("/home/pencilfoxs/00_new/History_Docent/03_Embedding/results")
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# API í‚¤ ë¡œë“œ
ENV_FILE = Path("/home/pencilfoxs/00_new/.env2")
if ENV_FILE.exists():
    with open(ENV_FILE, 'r') as f:
        for line in f:
            if line.startswith("GOOGLE_API_KEY="):
                os.environ["GOOGLE_API_KEY"] = line.split("=", 1)[1].strip()

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# âœ… í‰ê°€í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (7 Candidates)
MODELS = {
    # 1. Multilingual ê°•ì
    "BGE-m3": "BAAI/bge-m3",
    
    # 2. ìµœì‹  SOTA (Instruction ê¸°ë°˜)
    "Jina-v3": "jinaai/jina-embeddings-v3",
    
    # 3. ì„±ëŠ¥ ì¢‹ì€ ëŒ€í˜• ëª¨ë¸
    "GTE-large": "Alibaba-NLP/gte-large-en-v1.5",
    
    # 4. ê¾¸ì¤€íˆ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸
    "E5-large": "intfloat/multilingual-e5-large",
    
    # 5. í•œêµ­ì–´ íŠ¹í™” (Baseline)
    "Ko-SBERT": "jhgan/ko-sbert-nli", 
    
    # 6. Google Open Source (Gemma ê¸°ë°˜)
    # ì£¼ì˜: Transformers ìµœì‹  ë²„ì „ í•„ìš”, ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì œì™¸ ê°€ëŠ¥
    "EmbeddingGemma": "google/embedding-gemma-2b-en", 
    
    # 7. Google API (ìµœì‹ )
    "Gemini-API": "models/text-embedding-004" 
}

# -----------------------------------------------------------------------------
# í‰ê°€ í•¨ìˆ˜ (Evaluation Functions)
# -----------------------------------------------------------------------------

def load_benchmark_data():
    if not BENCHMARK_FILE.exists():
        raise FileNotFoundError(f"ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {BENCHMARK_FILE}")
    with open(BENCHMARK_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def get_gemini_embeddings(texts, model_name="models/text-embedding-004"):
    """Gemini REST APIë¥¼ ì‚¬ìš©í•œ ì„ë² ë”© ìƒì„±"""
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:batchEmbedContents?key={GOOGLE_API_KEY}"
    headers = {"Content-Type": "application/json"}
    
    all_embeddings = []
    batch_size = 50 # API í•œë„ ê³ ë ¤
    
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        payload = {
            "requests": [{"model": model_name, "content": {"parts": [{"text": text}]}} for text in batch_texts]
        }
        
        try:
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            if response.status_code != 200:
                print(f"Error API: {response.text}")
                # ì—ëŸ¬ ì‹œ 0ìœ¼ë¡œ ì±„ì›€ (ì¤‘ë‹¨ ë°©ì§€)
                all_embeddings.extend([np.zeros(768) for _ in batch_texts])
                continue
                
            result = response.json()
            embeddings = [e['values'] for e in result['embeddings']]
            all_embeddings.extend(embeddings)
            time.sleep(0.5) # Rate limit ë°©ì§€
        except Exception as e:
            print(f"Gemini API Error: {e}")
            all_embeddings.extend([np.zeros(768) for _ in batch_texts])
            
    return np.array(all_embeddings)

def get_embeddings(model_name, model_path, texts, device="cuda" if torch.cuda.is_available() else "cpu"):
    """ëª¨ë¸ë³„ ì„ë² ë”© ìƒì„± í•¨ìˆ˜"""
    print(f"   Creating embeddings for {len(texts)} texts with {model_name}...")
    start_time = time.time()
    
    # 1. Google Gemini API
    if "Gemini-API" in model_name:
        embeddings = get_gemini_embeddings(texts, model_path)
    
    # 2. Jina (Trust Remote Code í•„ìš”)
    elif "Jina" in model_name:
        model = SentenceTransformer(model_path, trust_remote_code=True, device=device)
        # Jina v3ëŠ” task ì§€ì • ê°€ëŠ¥ (retrieval.query / retrieval.passage)
        # ì—¬ê¸°ì„œëŠ” ì¿¼ë¦¬ì™€ ë¬¸ì„œ êµ¬ë¶„ ì—†ì´ ë‹¨ìˆœíˆ encode (ë˜ëŠ” ë¶„ê¸° ì²˜ë¦¬ ê°€ëŠ¥)
        embeddings = model.encode(texts, normalize_embeddings=True, batch_size=8)
        
    # 3. GTE (Trust Remote Code í•„ìš”)
    elif "GTE" in model_name:
        model = SentenceTransformer(model_path, trust_remote_code=True, device=device)
        embeddings = model.encode(texts, normalize_embeddings=True)

    # 4. E5 (Prefix í•„ìš”)
    elif "E5" in model_name:
        model = SentenceTransformer(model_path, device=device)
        # E5ëŠ” queryì™€ passageì— prefixê°€ ë¶™ì–´ì•¼ ì„±ëŠ¥ì´ ì¢‹ìŒ.
        # ë²¤ì¹˜ë§ˆí¬ êµ¬ì¡°ìƒ textsê°€ ì¿¼ë¦¬ì¸ì§€ ë¬¸ì„œì¸ì§€ êµ¬ë¶„í•˜ì—¬ ë„˜ê¸°ë©´ ì¢‹ìœ¼ë‚˜,
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì¼ê´„ ì²˜ë¦¬í•˜ê±°ë‚˜, í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì²˜ë¦¬í•´ì•¼ í•¨.
        # (ì´ í•¨ìˆ˜ëŠ” ë²”ìš©ì´ë¯€ë¡œ, ì…ë ¥ëœ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì„ë² ë”©)
        embeddings = model.encode(texts, normalize_embeddings=True)

    # 5. Embedding Gemma
    elif "Gemma" in model_name:
        # SentenceTransformer ì§€ì› ì—¬ë¶€ í™•ì¸ í•„ìš”, ë¯¸ì§€ì›ì‹œ HF Transformers ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” SentenceTransformerë¡œ ì‹œë„í•˜ë˜ ì•ˆë˜ë©´ ì˜ˆì™¸ ì²˜ë¦¬
        try:
            model = SentenceTransformer(model_path, trust_remote_code=True, device=device)
            embeddings = model.encode(texts, normalize_embeddings=True, batch_size=4) # ë©”ëª¨ë¦¬ ì£¼ì˜
        except Exception as e:
            print(f"Gemma ë¡œë“œ ì‹¤íŒ¨ (Transformersë¡œ ì‹œë„ í•„ìš”): {e}")
            return np.zeros((len(texts), 768)), 0

    # 6. ì¼ë°˜ ëª¨ë¸ (BGE, Ko-SBERT ë“±)
    else:
        model = SentenceTransformer(model_path, device=device)
        embeddings = model.encode(texts, normalize_embeddings=True)
        
    elapsed = time.time() - start_time
    speed = elapsed / len(texts) * 1000 # ms per text
    return np.array(embeddings), speed

def evaluate_model(model_name, model_path, dataset):
    queries = [item['query'] for item in dataset]
    golds = [item['gold_text'] for item in dataset]
    
    # E5 ëª¨ë¸ì¼ ê²½ìš° Prefix ì¶”ê°€ ì²˜ë¦¬
    if "E5" in model_name:
        q_texts = [f"query: {q}" for q in queries]
        c_texts = [f"passage: {g}" for g in golds]
    else:
        q_texts = queries
        c_texts = golds
    
    # 1. ì„ë² ë”© ìƒì„±
    q_embs, q_speed = get_embeddings(model_name, model_path, q_texts)
    c_embs, c_speed = get_embeddings(model_name, model_path, c_texts)
    
    # 2. ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(q_embs, c_embs)
    
    # 3. ì§€í‘œ ê³„ì‚°
    mrr_sum = 0
    hits_1 = 0
    hits_3 = 0
    hits_5 = 0
    
    n = len(queries)
    for i in range(n):
        target_idx = i # ië²ˆì§¸ ì§ˆë¬¸ì˜ ì •ë‹µì€ ië²ˆì§¸ ë¬¸ì„œ
        
        # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_indices = np.argsort(similarities[i])[::-1]
        
        # ìˆœìœ„ (1-based)
        rank = np.where(sorted_indices == target_idx)[0][0] + 1
        
        mrr_sum += 1.0 / rank
        if rank <= 1: hits_1 += 1
        if rank <= 3: hits_3 += 1
        if rank <= 5: hits_5 += 1
        
    metrics = {
        "Model": model_name,
        "MRR": round(mrr_sum / n, 3),
        "Recall@1": round(hits_1 / n, 3),
        "Recall@3": round(hits_3 / n, 3),
        "Recall@5": round(hits_5 / n, 3),
        "Latency(ms)": round((q_speed + c_speed) / 2, 1)
    }
    
    return metrics

# -----------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰
# -----------------------------------------------------------------------------
def main():
    print("ğŸš€ [Korean History Docent] ì„ë² ë”© ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print(f"ğŸ“‚ ë°ì´í„°ì…‹: {BENCHMARK_FILE}")
    
    try:
        dataset = load_benchmark_data()
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # í…ŒìŠ¤íŠ¸ìš© (ë„ˆë¬´ ë§ìœ¼ë©´ 50ê°œë§Œ ë¨¼ì € í•´ë³´ê¸° ê°€ëŠ¥)
    # dataset = dataset[:50] 
    print(f"ğŸ“Š í‰ê°€ ë°ì´í„° ìˆ˜: {len(dataset)}ê°œ")
    
    results = []
    
    for name, path in tqdm(MODELS.items(), desc="ëª¨ë¸ í‰ê°€ ì§„í–‰ ì¤‘"):
        try:
            metrics = evaluate_model(name, path, dataset)
            results.append(metrics)
            print(f"\n   âœ… {name}: MRR={metrics['MRR']}, R@1={metrics['Recall@1']} (Lat: {metrics['Latency(ms)']}ms)")
        except Exception as e:
            print(f"\n   âŒ {name} í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    # ê²°ê³¼ ì¶œë ¥
    if results:
        df = pd.DataFrame(results)
        df = df.sort_values(by="MRR", ascending=False)
        
        print("\nğŸ† [ìµœì¢… ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼] ğŸ†")
        print(df.to_markdown(index=False))
        
        csv_path = RESULTS_DIR / "benchmark_results_2000.csv"
        df.to_csv(csv_path, index=False)
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_path}")
    else:
        print("\nâŒ ìƒì„±ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()