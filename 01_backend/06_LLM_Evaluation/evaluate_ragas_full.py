#!/usr/bin/env python3
"""
RAGAS í‰ê°€ ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
- ëª©ì : ì „ì²´ Validation Set (2,223ê°œ)ì— ëŒ€í•œ RAGAS ì§€í‘œ ì¸¡ì •
- ì§€í‘œ: Context Recall, Context Precision, Faithfulness, Answer Relevancy
- íŠ¹ì§•: 50ê°œì”© ë°°ì¹˜ ì²˜ë¦¬, ì¬ê°œ ê¸°ëŠ¥, ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì§€ì›
"""

import os
import pandas as pd
import time
import json
from pathlib import Path
from tqdm import tqdm
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    context_recall,
    context_precision,
    faithfulness,
    answer_relevancy,
)
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
from datetime import datetime

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API Key)
env_path = Path("/home/pencilfoxs/00_new/.env2")
load_dotenv(env_path)

google_api_key = os.getenv("GOOGLE_AI_STUDIO_API_KEY")
if not google_api_key:
    raise ValueError("GOOGLE_AI_STUDIO_API_KEY not found in .env2 file")

os.environ["GOOGLE_API_KEY"] = google_api_key

# 2. ì„¤ì •
BASE_DIR = Path("/home/pencilfoxs/00_new/History_Docent")
INPUT_FILE = BASE_DIR / "06_LLM_Evaluation/results/llm_selected_model_full_test_with_contexts.csv"
OUTPUT_FILE = BASE_DIR / "06_LLM_Evaluation/results/ragas_evaluation_results.csv"
LOG_FILE = BASE_DIR / "06_LLM_Evaluation/results/ragas_evaluation.log"
PROGRESS_FILE = BASE_DIR / "06_LLM_Evaluation/results/ragas_evaluation_progress.json"

BATCH_SIZE = 50
MODEL_NAME = "gemini-2.0-flash"  # ì‹¬íŒê´€ ëª¨ë¸ (RPD ë¬´ì œí•œ)

# 3. ì‹¬íŒê´€(Judge) ëª¨ë¸ ì„¤ì •
print("=" * 60)
print("RAGAS í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
print("=" * 60)

print(f"\nğŸ”§ Judge ëª¨ë¸ ì„¤ì •: {MODEL_NAME}")
llm = ChatGoogleGenerativeAI(
    model=MODEL_NAME,
    temperature=0,  # í‰ê°€ëŠ” ì¼ê´€ì„± ìˆê²Œ
    top_p=1,
)
ragas_llm = LangchainLLMWrapper(llm)

# Embeddings ì„¤ì • (ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©, OpenAI API ë¶ˆí•„ìš”)
print(f"\nğŸ”§ Embeddings ëª¨ë¸ ì„¤ì •: BAAI/bge-m3")
ragas_embeddings = HuggingFaceEmbeddings(model="BAAI/bge-m3")

# 4. í‰ê°€ ì§€í‘œ ì„¤ì •
print(f"\nğŸ“Š í‰ê°€ ì§€í‘œ ì„¤ì •:")
print("   1. Context Recall (ê²€ìƒ‰ ì¬í˜„ìœ¨)")
print("   2. Context Precision (ê²€ìƒ‰ ì •ë°€ë„)")
print("   3. Faithfulness (ì‹ ë¢°ì„±)")
print("   4. Answer Relevancy (ë‹µë³€ ì ì ˆì„±)")

metrics = [
    context_recall,
    context_precision,
    faithfulness,
    answer_relevancy,
]

# LLM ì„¤ì • ì ìš©
for metric in metrics:
    metric.llm = ragas_llm

print("   âœ… ì§€í‘œ ì„¤ì • ì™„ë£Œ")

# 5. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ: {INPUT_FILE}")

if not INPUT_FILE.exists():
    raise FileNotFoundError(
        f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_FILE}\n"
        f"ë¨¼ì € prepare_ragas_data.pyë¥¼ ì‹¤í–‰í•˜ì—¬ contextsë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
    )

df = pd.read_csv(INPUT_FILE)
print(f"   ì´ {len(df)}ê°œ ì§ˆë¬¸ ë¡œë“œ ì™„ë£Œ")

# í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
required_columns = ['query', 'response', 'contexts', 'gold_text']
missing_columns = [col for col in required_columns if col not in df.columns]

if missing_columns:
    raise ValueError(
        f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}\n"
        f"í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}"
    )

# contextsê°€ JSON ë¬¸ìì—´ì¸ì§€ í™•ì¸ ë° ë³€í™˜
if df['contexts'].dtype == 'object':
    try:
        # JSON ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        df['contexts'] = df['contexts'].apply(
            lambda x: json.loads(x) if isinstance(x, str) and x.startswith('[') else (x if isinstance(x, list) else [])
        )
    except:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
        df['contexts'] = df['contexts'].apply(lambda x: [] if not isinstance(x, list) else x)

# RAGASê°€ ìš”êµ¬í•˜ëŠ” ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
df_ragas = df.copy()
df_ragas.rename(columns={
    'query': 'question',
    'response': 'answer',
    'gold_text': 'ground_truth'
}, inplace=True)

# contextsë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í™•ì‹¤íˆ ë³€í™˜ (RAGASëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ í•„ìš”)
df_ragas['contexts'] = df_ragas['contexts'].apply(
    lambda x: x if isinstance(x, list) else ([x] if isinstance(x, str) and x.strip() else [])
)

print("   âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")

# 6. ì¬ê°œ(Resume) ê¸°ëŠ¥ êµ¬í˜„
if OUTPUT_FILE.exists():
    print(f"\nğŸ”„ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ë°œê²¬: {OUTPUT_FILE}")
    existing_df = pd.read_csv(OUTPUT_FILE)
    processed_ids = set(existing_df['query_id'].tolist())
    df_to_process = df_ragas[~df_ragas['query_id'].isin(processed_ids)].copy()
    print(f"   ì´ë¯¸ ì²˜ë¦¬ë¨: {len(processed_ids)}ê°œ")
    print(f"   ë‚¨ì€ ì‘ì—…: {len(df_to_process)}ê°œ")
else:
    print(f"\nğŸ†• ìƒˆë¡œìš´ í‰ê°€ ì‹œì‘")
    df_to_process = df_ragas.copy()
    # ê²°ê³¼ íŒŒì¼ í—¤ë” ìƒì„±
    result_df_template = pd.DataFrame(columns=[
        'query_id', 'question', 'answer', 
        'context_recall', 'context_precision', 'faithfulness', 'answer_relevancy'
    ])
    result_df_template.to_csv(OUTPUT_FILE, index=False)
    print(f"   ê²°ê³¼ íŒŒì¼ ìƒì„±: {OUTPUT_FILE}")

if len(df_to_process) == 0:
    print("\nâœ… ëª¨ë“  í‰ê°€ê°€ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    exit(0)

print(f"\nğŸ“Š ì²˜ë¦¬ ëŒ€ìƒ: ì´ {len(df_ragas)}ê°œ ì¤‘ {len(df_to_process)}ê°œ ë‚¨ìŒ")

# 7. ë°°ì¹˜ ë‹¨ìœ„ í‰ê°€ ì‹¤í–‰
print(f"\nğŸš€ ë°°ì¹˜ í‰ê°€ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE})")
print(f"   ì´ {len(df_to_process)}ê°œ ì§ˆë¬¸, {((len(df_to_process) + BATCH_SIZE - 1) // BATCH_SIZE)}ê°œ ë°°ì¹˜")

total_batches = (len(df_to_process) + BATCH_SIZE - 1) // BATCH_SIZE
start_time = time.time()

for batch_idx in range(0, len(df_to_process), BATCH_SIZE):
    batch_num = (batch_idx // BATCH_SIZE) + 1
    batch_df = df_to_process.iloc[batch_idx:batch_idx + BATCH_SIZE].copy()
    
    print(f"\nğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch_df)}ê°œ ì§ˆë¬¸)")
    
    try:
        # RAGAS ë°ì´í„°ì…‹ ë³€í™˜
        # contextsê°€ ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨ (ê° ì§ˆë¬¸ë§ˆë‹¤ ì—¬ëŸ¬ ë¬¸ì„œ)
        ragas_data = {
            'question': batch_df['question'].tolist(),
            'answer': batch_df['answer'].tolist(),
            'contexts': batch_df['contexts'].tolist(),
            'ground_truth': batch_df['ground_truth'].tolist(),
        }
        ragas_dataset = Dataset.from_dict(ragas_data)
        
        # í‰ê°€ ì‹¤í–‰
        print("   ğŸ” RAGAS í‰ê°€ ì‹¤í–‰ ì¤‘...")
        results = evaluate(
            dataset=ragas_dataset,
            metrics=metrics,
            llm=ragas_llm,
            embeddings=ragas_embeddings,
            raise_exceptions=False,
        )
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        results_df = results.to_pandas()
        
        # ì›ë³¸ ì •ë³´(query_id)ì™€ ê²°í•©
        results_df['query_id'] = batch_df['query_id'].values
        
        # RAGAS ê²°ê³¼ ì»¬ëŸ¼ëª…ì„ ìš°ë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
        # RAGASëŠ” user_input, responseë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ë¥¼ question, answerë¡œ ë³€ê²½
        if 'user_input' in results_df.columns:
            results_df['question'] = results_df['user_input']
        if 'response' in results_df.columns:
            results_df['answer'] = results_df['response']
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        output_columns = ['query_id', 'question', 'answer']
        metric_columns = ['context_recall', 'context_precision', 'faithfulness', 'answer_relevancy']
        
        for col in metric_columns:
            if col in results_df.columns:
                output_columns.append(col)
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [col for col in output_columns if col in results_df.columns]
        results_df_output = results_df[available_columns].copy()
        
        # íŒŒì¼ì— ì¶”ê°€ (Append)
        results_df_output.to_csv(OUTPUT_FILE, mode='a', header=False, index=False)
        
        # ì§„í–‰ ìƒí™© ì €ì¥
        progress = {
            'batch_num': batch_num,
            'total_batches': total_batches,
            'processed': min(batch_num * BATCH_SIZE, len(df_to_process)),
            'total': len(df_to_process),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        with open(PROGRESS_FILE, 'w') as f:
            json.dump(progress, f, indent=2)
        
        # í‰ê·  ì ìˆ˜ ì¶œë ¥
        if metric_columns:
            available_metrics = [col for col in metric_columns if col in results_df.columns]
            if available_metrics:
                avg_scores = results_df[available_metrics].mean()
                print(f"   ğŸ“Š ë°°ì¹˜ í‰ê·  ì ìˆ˜:")
                for metric, score in avg_scores.items():
                    print(f"      - {metric}: {score:.4f}")
        
        # ì†ë„ ì •ë³´
        elapsed = time.time() - start_time
        avg_time_per_batch = elapsed / batch_num
        remaining_batches = total_batches - batch_num
        estimated_remaining = avg_time_per_batch * remaining_batches
        
        print(f"   â±ï¸  ê²½ê³¼ ì‹œê°„: {elapsed/60:.1f}ë¶„, ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining/60:.1f}ë¶„")
        
        # ì†ë„ ì¡°ì ˆ (ë„ˆë¬´ ë¹ ë¥´ë©´ ì ì‹œ ëŒ€ê¸°)
        time.sleep(1)
        
    except Exception as e:
        print(f"   âŒ ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡
        with open(LOG_FILE, 'a') as f:
            f.write(f"\n[ERROR] Batch {batch_num} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"{str(e)}\n")
            f.write(traceback.format_exc() + "\n")
        
        # ë‹¤ìŒ ë°°ì¹˜ë¡œ ë„˜ì–´ê°
        continue

# 8. ìµœì¢… ìš”ì•½
print("\n" + "=" * 60)
print("âœ… í‰ê°€ ì™„ë£Œ!")
print("=" * 60)

if OUTPUT_FILE.exists():
    final_df = pd.read_csv(OUTPUT_FILE)
    print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½:")
    print(f"   ì´ í‰ê°€ ì™„ë£Œ: {len(final_df)}ê°œ")
    
    metric_columns = ['context_recall', 'context_precision', 'faithfulness', 'answer_relevancy']
    available_metrics = [col for col in metric_columns if col in final_df.columns]
    
    if available_metrics:
        print(f"\n   ì „ì²´ í‰ê·  ì ìˆ˜:")
        for metric in available_metrics:
            avg_score = final_df[metric].mean()
            print(f"      - {metric}: {avg_score:.4f}")
    
    print(f"\nğŸ’¾ ê²°ê³¼ íŒŒì¼: {OUTPUT_FILE}")
else:
    print("\nâš ï¸  ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

print("\n" + "=" * 60)
