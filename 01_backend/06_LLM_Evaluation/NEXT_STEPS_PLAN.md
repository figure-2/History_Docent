# 다음 단계 작업 계획서

**작성 일시:** 2025-11-23 14:30

---

## 1. 현재 완료 상태 요약

### 1.1 완료된 작업

#### ✅ LLM 모델 선정 벤치마크
- **완료 일시:** 2025-11-23 13:35
- **작업 내용:**
  - 4개 로컬 LLM 모델 벤치마크 완료
  - 49개 샘플 (Keyword 16개, Context 16개, Abstract 17개)
  - 정량 평가 + 정성 평가 (20개 샘플) 완료
- **결과:**
  - 최종 선정 모델: `MLP-KTLim/llama-3-Korean-Bllossom-8B`
  - 성공률 100%, 평균 지연시간 6.98초
- **문서화:**
  - ✅ `README_LLM_Selection_Log.md` (작업 로그)
  - ✅ `SPEC_LLM_Strategy.md` (기술 명세서)
  - ✅ `results/llm_benchmark_summary.md` (정량 평가 종합)
  - ✅ `results/llm_qualitative_analysis.md` (정성 평가 분석)

#### ✅ RAG 파이프라인 구성
- **완료 일시:** 이전 단계
- **구성 요소:**
  - 임베딩 모델: `BAAI/bge-m3` (선정 완료)
  - 리트리버: Hybrid Weighted (Vector 60% + BM25 40%, Okt 형태소 분석)
  - 리랭커: `Dongjin-kr/ko-reranker` (선정 완료)
  - LLM: `MLP-KTLim/llama-3-Korean-Bllossom-8B` (선정 완료)

---

### 1.2 진행 중/대기 중인 작업

#### ⏸️ 전체 Validation Set 테스트
- **상태:** 중단됨 (GCP 인스턴스 종료)
- **목적:** 선정된 모델의 전체 성능 검증
- **데이터:** Validation Set 2,223개 질문
- **스크립트:** `test_selected_model.py` (생성 완료)
- **문제점:** 하드웨어 부족으로 인한 인스턴스 종료

#### ⏸️ RAGAS 평가
- **상태:** 미실행
- **목적:** Answer Relevance, Faithfulness, Context Recall 등 정량 평가
- **필요 작업:**
  - RAGAS 평가 스크립트 작성
  - LLM-as-a-Judge 설정 (Gemini API)
  - 평가 실행 및 결과 분석

#### ⏸️ Gated Repo 모델 테스트
- **상태:** 접근 권한 대기 중
- **모델:**
  - `LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct`
  - `google/gemma-2-27b-it`
- **필요 작업:**
  - HuggingFace에서 접근 권한 요청
  - 승인 후 `benchmark_gated_models.py` 실행

---

## 2. 다음 단계 작업 계획

### 2.1 우선순위 1: 전체 Validation Set 테스트 재실행

**목적:**
- 선정된 모델(Bllossom-8B)의 전체 성능 검증
- 49개 샘플이 아닌 전체 2,223개 질문으로 확장 평가

**작업 내용:**
1. **하드웨어 확인 및 최적화**
   - GCP 인스턴스 리소스 확인
   - 메모리 사용량 모니터링
   - 배치 처리 고려 (메모리 부족 방지)

2. **테스트 스크립트 개선**
   - `test_selected_model.py` 검토 및 수정
   - 중간 저장 로직 강화 (크래시 방지)
   - 진행 상황 모니터링 추가

3. **실행 및 결과 분석**
   - 백그라운드 실행 또는 배치 처리
   - 결과 저장 및 통계 분석
   - 성능 지표 비교 (49개 vs 2,223개)

**예상 소요 시간:**
- 실행 시간: 약 4-5시간 (2,223개 질문 × 평균 7초)
- 분석 시간: 1-2시간

**산출물:**
- `results/llm_selected_model_full_test.csv`
- 전체 성능 분석 보고서

---

### 2.2 우선순위 2: RAGAS 평가 실행

**목적:**
- 선정된 모델의 답변 품질을 정량적으로 평가
- Answer Relevance, Faithfulness, Context Recall 등 지표 측정

**작업 내용:**
1. **RAGAS 평가 스크립트 작성**
   - `evaluate_ragas.py` 작성
   - LLM-as-a-Judge 설정 (Gemini API)
   - 평가 메트릭 설정:
     - Answer Relevance
     - Faithfulness
     - Context Recall
     - Context Precision

2. **평가 데이터 준비**
   - 벤치마크 결과 로드
   - Ground Truth 데이터 준비
   - RAGAS 형식으로 변환

3. **평가 실행**
   - 샘플 데이터로 먼저 테스트 (50-100개)
   - 전체 데이터 평가 실행
   - 결과 분석 및 시각화

**예상 소요 시간:**
- 스크립트 작성: 2-3시간
- 평가 실행: 1-2시간 (샘플), 4-6시간 (전체)
- 분석: 1-2시간

**산출물:**
- `results/ragas_evaluation_results.csv`
- RAGAS 평가 보고서

---

### 2.3 우선순위 3: 통합 RAG 시스템 구축

**목적:**
- 선정된 모든 컴포넌트를 통합한 완전한 RAG 시스템 구축
- 실제 서비스 가능한 형태로 구현

**작업 내용:**
1. **통합 파이프라인 구현**
   - `integrated_rag_system.py` 작성
   - 모든 컴포넌트 통합:
     - 임베딩 모델 (BGE-m3)
     - 리트리버 (Hybrid Weighted)
     - 리랭커 (ko-reranker)
     - LLM (Bllossom-8B)

2. **API 서버 구축**
   - FastAPI 또는 Flask로 API 서버 구현
   - RESTful API 엔드포인트 제공
   - 요청/응답 형식 정의

3. **성능 최적화**
   - 모델 로딩 최적화 (캐싱)
   - 배치 처리 지원
   - 에러 핸들링 및 로깅

**예상 소요 시간:**
- 통합 파이프라인: 3-4시간
- API 서버: 2-3시간
- 최적화: 2-3시간

**산출물:**
- `integrated_rag_system.py`
- `rag_api_server.py`
- API 문서

---

### 2.4 우선순위 4: 프로덕션 배포 준비

**목적:**
- 실제 서비스 환경에 배포 가능한 형태로 준비
- 모니터링 및 로깅 시스템 구축

**작업 내용:**
1. **Docker 컨테이너화**
   - Dockerfile 작성
   - 의존성 관리
   - 환경 변수 설정

2. **모니터링 시스템**
   - 성능 지표 수집 (응답 시간, 성공률)
   - 로깅 시스템 구축
   - 에러 추적 및 알림

3. **문서화**
   - 배포 가이드 작성
   - API 문서 작성
   - 운영 매뉴얼 작성

**예상 소요 시간:**
- Docker화: 2-3시간
- 모니터링: 3-4시간
- 문서화: 2-3시간

**산출물:**
- `Dockerfile`
- `docker-compose.yml`
- 배포 가이드 문서

---

### 2.5 우선순위 5: 추가 평가 및 개선 (선택사항)

**목적:**
- 시스템 성능 지속적 개선
- 추가 모델 평가 (Gated Repo 모델)

**작업 내용:**
1. **Gated Repo 모델 테스트**
   - HuggingFace 접근 권한 요청
   - EXAONE, Gemma 모델 벤치마크
   - 결과 비교 분석

2. **프롬프트 엔지니어링**
   - 선정된 모델에 최적화된 프롬프트 탐색
   - Few-shot 예시 추가
   - A/B 테스트

3. **성능 모니터링 및 개선**
   - 실제 사용 데이터 수집
   - 사용자 피드백 분석
   - 지속적 개선

**예상 소요 시간:**
- Gated Repo 모델 테스트: 4-6시간
- 프롬프트 엔지니어링: 3-5시간
- 모니터링 및 개선: 지속적

**산출물:**
- 추가 모델 벤치마크 결과
- 프롬프트 최적화 보고서
- 개선 로그

---

## 3. 작업 일정 계획

### 3.1 단기 계획 (1주일 내)

**Day 1-2: 전체 Validation Set 테스트**
- [ ] 하드웨어 확인 및 최적화
- [ ] 테스트 스크립트 개선
- [ ] 전체 테스트 실행
- [ ] 결과 분석 및 보고서 작성

**Day 3-4: RAGAS 평가**
- [ ] RAGAS 평가 스크립트 작성
- [ ] 평가 데이터 준비
- [ ] 평가 실행 (샘플)
- [ ] 전체 평가 실행
- [ ] 결과 분석

**Day 5-7: 통합 시스템 구축**
- [ ] 통합 파이프라인 구현
- [ ] API 서버 구축
- [ ] 성능 최적화
- [ ] 테스트 및 검증

### 3.2 중기 계획 (2-3주 내)

**Week 2: 프로덕션 배포 준비**
- [ ] Docker 컨테이너화
- [ ] 모니터링 시스템 구축
- [ ] 문서화 완료
- [ ] 배포 테스트

**Week 3: 추가 평가 및 개선**
- [ ] Gated Repo 모델 테스트 (권한 승인 시)
- [ ] 프롬프트 엔지니어링
- [ ] 성능 모니터링 시작

---

## 4. 리스크 및 대응 방안

### 4.1 하드웨어 부족 문제

**리스크:**
- GCP 인스턴스 종료 (하드웨어 부족)
- 전체 Validation Set 테스트 중단

**대응 방안:**
1. **배치 처리:**
   - 전체 데이터를 작은 배치로 나누어 처리
   - 각 배치 완료 후 중간 저장
   - 메모리 사용량 모니터링

2. **리소스 최적화:**
   - 불필요한 모델 언로드
   - 메모리 정리 강화
   - GPU 메모리 사용량 최소화

3. **대안 계획:**
   - 샘플링 테스트 (500-1000개 샘플)
   - 클라우드 서비스 활용 (Colab Pro 등)

### 4.2 API Rate Limit 문제

**리스크:**
- Gemini API Rate Limit 초과
- RAGAS 평가 중단

**대응 방안:**
1. **대기 시간 증가:**
   - 요청 간 대기 시간 증가 (6초 이상)
   - Exponential Backoff 구현

2. **배치 처리:**
   - 여러 요청을 배치로 묶어 처리
   - Rate Limit 모니터링

3. **대안 LLM 사용:**
   - 다른 API 서비스 활용
   - 로컬 LLM 사용 (품질 저하 가능)

### 4.3 Gated Repo 접근 권한

**리스크:**
- HuggingFace 접근 권한 승인 지연
- 추가 모델 테스트 불가

**대응 방안:**
1. **권한 요청:**
   - HuggingFace에서 즉시 접근 권한 요청
   - 승인 대기 중 다른 작업 진행

2. **대안 모델:**
   - 접근 가능한 다른 모델로 대체
   - 현재 선정된 모델로 진행

---

## 5. 성공 기준

### 5.1 전체 Validation Set 테스트

**성공 기준:**
- ✅ 전체 2,223개 질문에 대한 답변 생성 완료
- ✅ 성공률 95% 이상 유지
- ✅ 평균 지연시간 10초 이하 유지
- ✅ 결과 분석 및 보고서 작성 완료

### 5.2 RAGAS 평가

**성공 기준:**
- ✅ 4개 메트릭 (Answer Relevance, Faithfulness, Context Recall, Context Precision) 평가 완료
- ✅ 평균 점수 0.7 이상
- ✅ 평가 결과 분석 및 보고서 작성 완료

### 5.3 통합 RAG 시스템

**성공 기준:**
- ✅ 모든 컴포넌트 통합 완료
- ✅ API 서버 정상 작동
- ✅ 응답 시간 10초 이하
- ✅ 에러 핸들링 및 로깅 구현 완료

### 5.4 프로덕션 배포 준비

**성공 기준:**
- ✅ Docker 컨테이너 정상 작동
- ✅ 모니터링 시스템 구축 완료
- ✅ 배포 가이드 및 문서 작성 완료
- ✅ 배포 테스트 통과

---

## 6. 필요한 리소스

### 6.1 하드웨어

**필수:**
- GPU: NVIDIA A100 40GB 이상
- RAM: 64GB 이상
- 디스크: 500GB 이상 (SSD 권장)

**권장:**
- 멀티 GPU 환경 (Tensor Parallelism)
- 고속 네트워크 (모델 다운로드)

### 6.2 소프트웨어

**필수:**
- Python 3.8 이상
- CUDA 12.2 이상
- Docker (배포용)

**API 키:**
- Google Gemini API 키 (RAGAS 평가용)
- HuggingFace API 토큰 (Gated Repo 접근용)

### 6.3 데이터

**필수:**
- Validation Set (2,223개 질문)
- 벤치마크 결과 데이터
- Ground Truth 데이터 (RAGAS 평가용)

---

## 7. 다음 작업 즉시 시작 가능 항목

### 7.1 즉시 시작 가능

1. **전체 Validation Set 테스트 재실행**
   - 스크립트 준비 완료 (`test_selected_model.py`)
   - 하드웨어 확인 후 즉시 실행 가능

2. **RAGAS 평가 스크립트 작성**
   - 이전 프로젝트 참고 가능
   - 독립적으로 진행 가능

3. **통합 RAG 시스템 구축**
   - 모든 컴포넌트 선정 완료
   - 통합 파이프라인 구현 시작 가능

### 7.2 대기 필요

1. **Gated Repo 모델 테스트**
   - HuggingFace 접근 권한 승인 대기
   - 승인 후 즉시 실행 가능

2. **프로덕션 배포**
   - 통합 시스템 완료 후 진행
   - 모니터링 시스템 구축 필요

---

## 8. 권장 작업 순서

### Phase 1: 검증 완료 (1주일)
1. 전체 Validation Set 테스트
2. RAGAS 평가
3. 결과 분석 및 보고서 작성

### Phase 2: 시스템 구축 (1주일)
1. 통합 RAG 시스템 구축
2. API 서버 구축
3. 성능 최적화

### Phase 3: 배포 준비 (1주일)
1. Docker 컨테이너화
2. 모니터링 시스템 구축
3. 문서화 완료

### Phase 4: 개선 및 확장 (지속적)
1. 추가 모델 평가
2. 프롬프트 엔지니어링
3. 성능 모니터링 및 개선

---

## 9. 체크리스트

### 9.1 즉시 실행 가능 항목

- [ ] 전체 Validation Set 테스트 재실행
  - [ ] 하드웨어 확인
  - [ ] 스크립트 검토 및 수정
  - [ ] 실행 및 모니터링
  - [ ] 결과 분석

- [ ] RAGAS 평가 스크립트 작성
  - [ ] 스크립트 작성
  - [ ] 평가 데이터 준비
  - [ ] 샘플 평가 실행
  - [ ] 전체 평가 실행

### 9.2 다음 단계 항목

- [ ] 통합 RAG 시스템 구축
- [ ] API 서버 구축
- [ ] Docker 컨테이너화
- [ ] 모니터링 시스템 구축
- [ ] 문서화 완료

### 9.3 선택적 항목

- [ ] Gated Repo 모델 테스트
- [ ] 프롬프트 엔지니어링
- [ ] 성능 모니터링 및 개선

---

## 10. 결론

현재 LLM 모델 선정 작업이 완료되었으며, 다음 단계로 전체 Validation Set 테스트와 RAGAS 평가를 진행하여 선정된 모델의 성능을 검증하고, 이후 통합 RAG 시스템을 구축하여 실제 서비스 가능한 형태로 완성하는 것이 목표입니다.

**즉시 시작 가능한 작업:**
1. 전체 Validation Set 테스트 재실행
2. RAGAS 평가 스크립트 작성 및 실행

**예상 완료 시점:**
- Phase 1 (검증 완료): 1주일 내
- Phase 2 (시스템 구축): 2주일 내
- Phase 3 (배포 준비): 3주일 내

---

**작성자:** AI Assistant  
**작성 일시:** 2025-11-23 14:30  
**상태:** ✅ 계획 수립 완료, 실행 대기 중

