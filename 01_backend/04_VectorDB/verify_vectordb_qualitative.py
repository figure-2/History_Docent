"""
ChromaDB ì •ì„± í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (Qualitative Analysis)
- ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ 50ê°œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ì—¬ ì‹¬ì¸µ ë¶„ì„ ìˆ˜í–‰
- ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆ(Relevance)ì„ ìœ¡ì•ˆìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import torch
from sentence_transformers import SentenceTransformer
import json
import random
import time

# -----------------------------------------------------------------------------
# ì„¤ì •
# -----------------------------------------------------------------------------
BASE_DIR = Path("/home/pencilfoxs/00_new/History_Docent")
VECTORDB_DIR = BASE_DIR / "04_VectorDB/chroma_db"
COLLECTION_NAME = "korean_history_chunks"
MODEL_NAME = "BAAI/bge-m3"
BENCHMARK_DATA = BASE_DIR / "03_Embedding/data/korean_history_benchmark_2000.json"
OUTPUT_REPORT = BASE_DIR / "04_VectorDB/qualitative_analysis_report.txt"

SAMPLE_SIZE = 50

# -----------------------------------------------------------------------------
# ë©”ì¸ ë¡œì§
# -----------------------------------------------------------------------------
def main():
    print("=" * 60)
    print(f"ChromaDB ì •ì„± í‰ê°€ ì‹œì‘ (ìƒ˜í”Œ {SAMPLE_SIZE}ê°œ)")
    print("=" * 60)
    
    # 1. ë°ì´í„°ì…‹ ë¡œë“œ ë° ìƒ˜í”Œë§
    print(f"\nğŸ“‚ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: {BENCHMARK_DATA}")
    with open(BENCHMARK_DATA, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"   ì´ {len(data)}ê°œ ë°ì´í„° ì¤‘ {SAMPLE_SIZE}ê°œ ìƒ˜í”Œë§...")
    
    # ì†ŒìŠ¤ë³„ë¡œ ê³¨ê³ ë£¨ ì„ì–´ì„œ ë½‘ê¸° ìœ„í•´ ì…”í”Œ í›„ ì„ íƒ
    random.seed(42)  # ì¬í˜„ì„±ì„ ìœ„í•´ ì‹œë“œ ê³ ì •
    random.shuffle(data)
    samples = data[:SAMPLE_SIZE]
    
    # 2. ChromaDB ë° ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ“‚ ChromaDB ë° ëª¨ë¸ ë¡œë“œ ì¤‘...")
    client = chromadb.PersistentClient(
        path=str(VECTORDB_DIR),
        settings=Settings(anonymized_telemetry=False)
    )
    collection = client.get_collection(name=COLLECTION_NAME)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = SentenceTransformer(MODEL_NAME, device=device)
    print(f"   âœ… ë¡œë“œ ì™„ë£Œ (Device: {device})")
    
    # 3. í‰ê°€ ì‹¤í–‰ ë° ë¦¬í¬íŠ¸ ì‘ì„±
    print(f"\nğŸš€ ì •ì„± í‰ê°€ ì‹¤í–‰ ì¤‘...")
    
    with open(OUTPUT_REPORT, 'w', encoding='utf-8') as report:
        report.write(f"# ChromaDB ì •ì„± í‰ê°€ ë³´ê³ ì„œ\n")
        report.write(f"- ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.write(f"- ëª¨ë¸: {MODEL_NAME}\n")
        report.write(f"- ìƒ˜í”Œ ìˆ˜: {SAMPLE_SIZE}ê°œ\n")
        report.write("-" * 80 + "\n\n")
        
        success_count = 0
        rank1_count = 0
        rank3_count = 0
        rank5_count = 0
        
        for i, sample in enumerate(samples, 1):
            query = sample['query']
            gold_chunk_id = sample['chunk_id']
            
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = model.encode(query, normalize_embeddings=True).tolist()
            
            # ê²€ìƒ‰ (Top 5)
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=5
            )
            
            # ê²°ê³¼ ë¶„ì„
            retrieved_ids = results['ids'][0]
            distances = results['distances'][0]
            documents = results['documents'][0]
            metadatas = results['metadatas'][0]
            
            is_success = gold_chunk_id in retrieved_ids
            if is_success:
                success_count += 1
                rank = retrieved_ids.index(gold_chunk_id) + 1
                if rank == 1:
                    rank1_count += 1
                if rank <= 3:
                    rank3_count += 1
                if rank <= 5:
                    rank5_count += 1
                status_icon = "âœ… ì„±ê³µ"
            else:
                rank = "X"
                status_icon = "âŒ ì‹¤íŒ¨"
                
            # í„°ë¯¸ë„ ì¶œë ¥ (ì§„í–‰ ìƒí™©)
            print(f"[{i}/{SAMPLE_SIZE}] {status_icon} (Rank: {rank}) - {query[:40]}...")

            # ë¦¬í¬íŠ¸ ì‘ì„±
            report.write(f"## Case {i}: {status_icon} (Rank: {rank})\n")
            report.write(f"**Q:** {query}\n")
            report.write(f"**ì •ë‹µ ID:** {gold_chunk_id}\n\n")
            
            report.write(f"**ê²€ìƒ‰ ê²°ê³¼ (Top 3):**\n")
            for j in range(3):  # ìƒìœ„ 3ê°œë§Œ ìƒì„¸ ì¶œë ¥
                if j >= len(retrieved_ids):
                    break
                
                rid = retrieved_ids[j]
                dist = distances[j]
                doc = documents[j].replace("\n", " ")[:150]  # ì¤„ë°”ê¿ˆ ì œê±° ë° ê¸¸ì´ ì œí•œ
                source = metadatas[j].get('source', 'Unknown')
                page = metadatas[j].get('page', 'N/A')
                
                match_mark = "ğŸ‘ˆ ì •ë‹µ" if rid == gold_chunk_id else ""
                report.write(f"{j+1}. [{rid}] (Dist: {dist:.4f}) [{source}, p.{page}] - {doc}... {match_mark}\n")
            
            report.write("\n" + "-" * 40 + "\n\n")
            
        # ìµœì¢… ìš”ì•½
        accuracy = (success_count / SAMPLE_SIZE) * 100
        recall1 = (rank1_count / SAMPLE_SIZE) * 100
        recall3 = (rank3_count / SAMPLE_SIZE) * 100
        recall5 = (rank5_count / SAMPLE_SIZE) * 100
        
        summary = f"\n# ìµœì¢… ìš”ì•½\n"
        summary += f"- ì´ ìƒ˜í”Œ: {SAMPLE_SIZE}ê°œ\n"
        summary += f"- Recall@1: {rank1_count}ê°œ ({recall1:.1f}%)\n"
        summary += f"- Recall@3: {rank3_count}ê°œ ({recall3:.1f}%)\n"
        summary += f"- Recall@5: {success_count}ê°œ ({accuracy:.1f}%)\n"
        report.write(summary)
        print("\n" + summary)

    print(f"\nğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {OUTPUT_REPORT}")

if __name__ == "__main__":
    main()

